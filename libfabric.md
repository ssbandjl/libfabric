# libfabric开发笔记



## 编程指南

https://ofiwg.github.io/libfabric/main/man/fi_guide.7.html



fi_guide(7) Libfabric 程序员指南
姓名
fi_guide - libfabric 程序员指南

概述
libfabric 是一个通信库框架，旨在满足高性能计算 (HPC) 应用程序的性能和可扩展性要求。 libfabric 定义了通信接口，可在应用程序和底层网络服务之间实现紧密的语义映射。 具体来说，libfabric软件接口是与网络硬件提供商和应用程序开发商共同设计的，重点关注HPC用户的需求。

本指南描述了 libfabric 架构和接口。 由于指南篇幅较长，已分为多页。 这些部分是：

简介 fi_intro(7)
本节深入了解 libfabric 设计的动机以及通过 API 公开的底层网络功能。
架构 fi_arch(7)
这描述了 libfabric 的公开架构，包括对象模型及其相关操作
设置 fi_setup(7)
这提供了使用 libfabric API 的基本引导和设置。



# fi_intro(7) Libfabric 程序员指南 - 简介

# 姓名

fi_intro - libfabric 介绍

# 概述

本介绍是 libfabric 程序员指南的一部分。参见 [`fi_guide`(7)](https://ofiwg.github.io/libfabric/main/man/fi_guide.7.html)。本节深入了解 libfabric 设计的动机以及通过 API 公开的底层网络功能。

# 套接字通信回顾

套接字 API 是一种广泛使用的网络 API。本指南假设读者具有套接字编程的应用知识。它自始至终都引用了基于套接字的通信，以帮助解释 libfabric 概念以及它们与套接字 API 的关联或区别。需要明确的是，本指南的目的不是批评套接字 API，而是引用套接字作为起点，以解释某些网络功能或限制。以下部分提供了套接字语义的高级概述以供参考。

## 连接 (TCP) 通信

使用最广泛的套接字类型是 SOCK_STREAM。这种套接字通常在 TCP/IP 上运行，因此通常称为“TCP”套接字。TCP 套接字是面向连接的，需要在数据传输之前进行显式连接设置。单个 TCP 套接字只能将数据传输到单个对等套接字。与多个对等点通信需要每个对等点使用一个套接字。

使用 TCP 套接字的应用程序通常被标记为客户端或服务器。服务器应用程序侦听连接请求，并在连接请求发生时接受它们。另一方面，客户端发起与服务器的连接。在套接字API术语中，服务器调用listen()，客户端调用connect()。建立连接后，客户端和服务器之间的数据传输类似。以下代码段重点介绍了示例客户端和服务器的一般流程。为了简洁起见，省略了错误处理和套接字 API 的一些微妙之处。

```
/* Example server code flow to initiate listen */
struct addrinfo *ai, hints;
int listen_fd;

memset(&hints, 0, sizeof hints);
hints.ai_socktype = SOCK_STREAM;
hints.ai_flags = AI_PASSIVE;
getaddrinfo(NULL, "7471", &hints, &ai);

listen_fd = socket(ai->ai_family, SOCK_STREAM, 0);
bind(listen_fd, ai->ai_addr, ai->ai_addrlen);
freeaddrinfo(ai);

fcntl(listen_fd, F_SETFL, O_NONBLOCK);
listen(listen_fd, 128);
```

在此示例中，服务器将侦听系统中所有地址的端口 7471 上的连接请求。对 getaddrinfo() 的调用用于形成本地套接字地址。节点参数设置为 NULL，这会导致返回通配符 IP 地址。该端口被硬编码为 7471。AI_PASSIVE 标志表示该地址将由连接的侦听端使用。也就是说，地址信息应该是相对于本地节点的。

此示例适用于 IPv4 和 IPv6。getaddrinfo() 调用将地址格式从服务器中抽象出来，从而提高了其可移植性。使用 getaddrinfo() 返回的数据，服务器分配一个 SOCK_STREAM 类型的套接字，并将该套接字绑定到端口 7471。

实际上，大多数企业级应用程序都使用非阻塞套接字。这是单个应用程序线程管理多个套接字连接所必需的。fcntl() 命令将侦听套接字设置为非阻塞模式。这将影响服务器处理连接请求的方式（如下所示）。最后，服务器通过调用listen开始监听连接请求。在调用listen之前，到达服务器的连接请求将被操作系统拒绝。

```
/* Example client code flow to start connection */
struct addrinfo *ai, hints;
int client_fd;

memset(&hints, 0, sizeof hints);
hints.ai_socktype = SOCK_STREAM;
getaddrinfo("10.31.20.04", "7471", &hints, &ai);

client_fd = socket(ai->ai_family, SOCK_STREAM, 0);
fcntl(client_fd, F_SETFL, O_NONBLOCK);

connect(client_fd, ai->ai_addr, ai->ai_addrlen);
freeaddrinfo(ai);
```

与服务器类似，客户端也使用 getaddrinfo()。由于未指定 AI_PASSIVE 标志，因此给定地址将被视为目标地址。客户端期望到达 IP 地址 10.31.20.04、端口 7471 的服务器。在本例中，地址被硬编码到客户端中。更典型的是，地址将通过命令行、配置文件或从服务提供给客户端。通常，端口号是众所周知的，客户端将通过名称找到服务器，DNS（域名服务）提供名称到地址解析。幸运的是，getaddrinfo 调用可用于将主机名转换为 IP 地址。

无论是直接向客户端提供服务器的网络地址还是必须将其转换为网络地址的名称，用于向客户端提供此信息的机制差异很大。常用的一种简单机制是用户使用命令行选项提供服务器的地址。对于与数百到数百万对等进程通信的应用程序来说，告诉应用程序其对等进程所在位置的问题会显着增加，通常需要单独的专用应用程序来解决。对于典型的客户端-服务器套接字应用程序，这不是问题，因此我们将推迟更多讨论。

使用 getaddrinfo() 结果，客户端打开一个套接字，将其配置为非阻塞模式，并发起连接请求。此时，网络堆栈已向服务器发送建立连接的请求。由于套接字已设置为非阻塞，因此 connect 调用将立即返回，而不会等待连接建立。因此，此时任何发送数据的尝试都可能会失败。

```
/* Example server code flow to accept a connection */
struct pollfd fds;
int server_fd;

fds.fd = listen_fd;
fds.events = POLLIN;

poll(&fds, -1);

server_fd = accept(listen_fd, NULL, 0);
fcntl(server_fd, F_SETFL, O_NONBLOCK);
```

使用非阻塞套接字的应用程序使用 select()、poll() 或等效项（例如 epoll()）来接收套接字何时准备好发送或接收数据的通知。在这种情况下，服务器希望知道监听套接字何时有连接请求需要处理。它将侦听套接字添加到轮询集中，然后等待连接请求到达（即 POLLIN 为 true）。poll() 调用会阻塞，直到在套接字上设置 POLLIN。POLLIN 表示套接字有数据要接受。由于这是一个监听套接字，因此数据是一个连接请求。服务器通过调用accept()接受请求。这将向服务器返回一个新的套接字，该套接字已准备好进行数据传输。最后，服务器将新套接字设置为非阻塞模式。

```
/* Example client code flow to establish a connection */
struct pollfd fds;
int err;
socklen_t len;

fds.fd = client_fd;
fds.events = POLLOUT;

poll(&fds, -1);

len = sizeof err;
getsockopt(client_fd, SOL_SOCKET, SO_ERROR, &err, &len);
```

当客户端的连接套接字“准备好发送数据”时（即 POLLOUT 为 true），客户端会收到连接请求已完成的通知。poll() 调用会阻塞，直到在套接字上设置 POLLOUT，这表明连接尝试已完成。请注意，连接请求可能已完成但出现错误，并且客户端仍需要检查连接尝试是否成功。这不会通过 poll() 调用传达给应用程序。getsockopt() 调用用于检索连接尝试的结果。如果本示例中的 err 设置为 0，则连接尝试成功。套接字现在已准备好发送和接收数据。

连接建立后，客户端和服务器发送或接收数据的过程是相同的。下面的示例仅在客户端或服务器应用程序使用的套接字变量的名称上有所不同。

```
/* Example of client sending data to server */
struct pollfd fds;
size_t offset, size, ret;
char buf[4096];

fds.fd = client_fd;
fds.events = POLLOUT;

size = sizeof(buf);
for (offset = 0; offset < size; ) {
    poll(&fds, -1);

    ret = send(client_fd, buf + offset, size - offset, 0);
    offset += ret;
}
```

网络通信涉及在连接的发送端和接收端缓冲数据。TCP 使用基于信用的方案来管理流量控制，以确保连接的接收端有足够的缓冲区空间来接受传入数据。此流量控制通过套接字 API 对应用程序隐藏。因此，基于流的套接字可能无法传输应用程序请求作为单个操作的一部分发送的所有数据。

在此示例中，客户端维护其希望发送的缓冲区的偏移量。随着数据被网络接受，偏移量会增加。然后，客户端等待网络准备好接受更多数据，然后再尝试另一次传输。poll() 操作支持这一点。当客户端套接字准备好接收数据时，它将 POLLOUT 设置为 true。这表明发送将传输一些额外的数据量。客户端发出 send() 请求以获取它希望传输的剩余缓冲区量。如果 send() 传输的数据少于请求的数据，则客户端会更新偏移量，等待网络准备就绪，然后重试。

```
/* Example of server receiving data from client */
struct pollfd fds;
size_t offset, size, ret;
char buf[4096];

fds.fd = server_fd;
fds.events = POLLIN;

size = sizeof(buf);
for (offset = 0; offset < size; ) {
    poll(&fds, -1);

    ret = recv(client_fd, buf + offset, size - offset, 0);
    offset += ret;
}
```

接收数据的流程与发送数据的流程类似。由于套接字的流式传输性质，无法保证接收方将在单个调用中获取所有可用数据。相反，服务器必须等到套接字准备好接收数据 (POLLIN)，然后才能调用 receive 来获取可用的数据。在此示例中，服务器知道需要从客户端获取 4 KB 的数据。更一般地，客户端和服务器将在所有消息开始时交换通信协议标头，并且标头将包括消息的大小。

值得注意的是，前面两个例子的编写是为了简单易懂。考虑到性能时，它们的构造很差。在这两种情况下，应用程序始终在数据传输调用（发送或接收）之前使用 poll()。其影响是，即使网络已准备好传输数据或有数据排队等待接收，应用程序也始终会遇到 poll() 的延迟和处理开销。更好的方法是在进入 for() 循环之前调用 send() 或 receive()，并且仅在需要时才进入循环。

## 无连接 (UDP) 通信

如前所述，TCP 套接字是面向连接的。它们可用于在两个进程之间进行通信。对于需要与数千个对等进程通信的并行应用程序来说，管理如此多的并发套接字的开销可能会很大，以至于随着添加更多进程，应用程序性能可能会下降。

为了支持与大量对等点的通信，或者对于不需要可靠通信开销的应用程序，套接字提供了另一个常用的套接字选项，SOCK_DGRAM。数据报是不可靠的、无连接的消息。最常见的 SOCK_DGRAM 套接字类型通过 UDP/IP 运行。因此，数据报套接字通常称为 UDP 套接字。

UDP 套接字使用与上述 TCP 套接字相同的套接字 API；然而，沟通行为有所不同。首先，使用 UDP 套接字的应用程序在向对等方发送消息之前不需要连接到对等方。目标地址被指定为发送操作的一部分。第二个主要区别是消息不能保证到达对等点。交换机、路由器或远程 NIC 中的网络拥塞可能会丢弃该消息，并且不会尝试重新发送该消息。发件人不会收到消息已到达或已被丢弃的通知。TCP 和 UDP 套接字之间的另一个区别是允许的传输的最大大小。UDP 套接字将消息限制为最多 64k，但实际上，应用程序使用更小的大小，通常与网络 MTU 大小对齐（例如，

大多数UDP套接字的使用都用sendto()和recvfrom()代替套接字send()/recv()调用。

```
/* Example send to peer at given IP address and UDP port */
struct addrinfo *ai, hints;

memset(&hints, 0, sizeof hints);
hints.ai_socktype = SOCK_DGRAM;
getaddrinfo("10.31.20.04", "7471", &hints, &ai);

ret = sendto(client_fd, buf, size, 0, ai->ai_addr, ai->ai_addrlen);
```

在上面的例子中，我们使用 getaddrinfo() 将给定的 IP 地址和 UDP 端口号转换为 sockaddr。它被传递到 sendto() 调用中以指定消息的目的地。请注意此流程与 TCP 套接字流程之间的相似之处。recvfrom() 调用允许我们接收消息发送者的地址。请注意，与流式套接字不同，成功时网络会接受整个消息。由size参数指定的buf参数的所有内容都已被网络层排队。

尽管未显示，但应用程序可以在调用 sendto() 之前调用 poll() 或等效函数，以确保套接字已准备好接受新数据。类似地，可以在调用 recvfrom() 之前使用 poll() 来检查是否有数据可供从套接字读取。

```
/* Example receive a message from a peer */
struct sockaddr_in addr;
socklen_t addrlen;

addrlen = sizeof(addr);
ret = recvfrom(client_fd, buf, size, 0, &addr, &addrlen);
```

此示例将接收来自任何对等方的任何传入消息。对等点的地址将在 addr 参数中提供。在这种情况下，我们只提供足够的空间来记录和 IPv4 地址（受我们使用 struct sockaddr_in 的限制）。支持 IPv6 地址只需要传入更大的地址缓冲区（例如映射到 struct sockaddr_in6）。

## 优点

套接字 API 有两个显着的优点。首先，它可以在多种操作系统和平台上使用，并且可以在绝大多数可用的网络硬件上运行。它甚至可以在同一系统上的进程之间进行通信，而无需任何网络硬件。它很容易成为事实上的网络 API。这本身就使其具有吸引力。

第二个关键优点是它相对容易编程。这一点的重要性不容忽视。网络 API 提供对更高性能功能的访问，但难以正确或良好地编程，通常会导致应用程序性能降低。这与用 C 或 C++ 等高级语言编写应用程序与汇编没有什么不同。尽管直接编写汇编语言有望*获得* 更好的性能，但对于绝大多数开发人员来说，如果用 C 或 C++ 编写并使用优化的编译器，他们的应用程序将性能更好。在选择套接字的替代 API 之前，应用程序应该明确需要高性能网络。

## 缺点

当考虑与高性能网络有关的套接字 API 的问题时，我们将讨论限制在两种最常见的套接字类型：流式传输 (TCP) 和数据报 (UDP)。

大多数应用程序都要求网络数据可靠地发送。这总是意味着使用面向连接的 TCP 套接字。TCP 套接字以字节流的形式传输数据。然而，许多应用程序都是基于消息进行操作的。结果是应用程序经常插入仅用于将应用程序消息与字节流相互转换的标头。这些标头消耗额外的网络带宽和处理能力。接口的流特性还导致应用程序使用循环（如上面的示例所示）来发送和接收更大的消息。如果应用程序管理数百或数千个对等点的套接字，这些循环的复杂性可能会非常高。

上述示例强调的另一个问题涉及网络流量的异步性质。当使用可靠的传输时，仅仅将应用程序的数据放置到网络上是不够的。如果网络繁忙，则可能会丢弃数据包，或者数据可能会在传输过程中损坏。数据必须保留到对方确认为止，以便在需要时可以重新发送。套接字 API 的定义使得应用程序在套接字调用返回后拥有其内存缓冲区的内容。

例如，如果我们检查套接字 send() 调用，一旦 send() 返回，应用程序就可以自由修改其缓冲区。网络实现有几个选项。一种选择是发送调用将数据直接放置到网络上。然后，调用必须在返回给用户之前阻塞，直到对等方确认已收到数据，此时 send() 可以返回。这种方法的明显问题是应用程序在 send() 调用中被阻塞，直到对等方的网络堆栈可以处理数据并生成确认为止。这可能是应用程序被阻止并且无法处理其他工作（例如响应来自其他客户端的消息）的很长一段时间。这种做法是不可行的。

更好的选择是调用 send() 将应用程序的数据复制到内部缓冲区中。然后从该缓冲区发出数据传输，这允许在发生故障时重试操作。在这种情况下，send() 调用不会被阻止，但即使没有任何错误，所有通过网络传递的数据都会导致内存复制到本地缓冲区。

允许立即重用数据缓冲区是套接字 API 的一项功能，使其保持简单且易于编程。然而，这样的功能可能会对网络性能产生负面影响。对于网络或内存有限的应用程序，甚至是关心功耗的应用程序，替代 API 可能很有吸引力。

一个稍微隐蔽的问题出现在为 UDP 套接字设计的套接字 API 中。这个问题是由于 API 设计是为了易用性而设计的，导致实现效率低下。为了让应用程序向对等方发送数据，它需要提供对等方的 IP 地址和 UDP 端口号。这涉及到将 sockaddr 结构传递给 sendto() 和 recvfrom() 调用。然而，IP地址是更高级别的网络层地址。为了在系统之间传输数据，需要低级链路层地址，例如以太网地址。网络层必须在每次发送操作时将 IP 地址映射到以太网地址。当扩展到数千个对等点时，每次发送调用的开销可能会很大。

最后，由于套接字 API 通常与 TCP 和 UDP 协议结合考虑，因此有意将其与底层网络硬件实现（包括 NIC、交换机和路由器）分离。因此，对可用网络功能的访问受到 API 可支持的功能的限制。

这里值得注意的是，某些操作系统支持可用于与 TCP 和 UDP 套接字交互的增强 API。例如，Linux 支持名为 io_uring 的接口，Windows 有异步套接字 API。这些 API 可以帮助缓解上述一些问题。然而，应用程序仍然会受到 TCP 和 UDP 协议提供的功能的限制。

# 高性能网络

通过在高性能网络背景下分析套接字 API，我们可以开始看到网络 API 所需的一些功能。

## 避免内存复制

套接字 API 实现通常会导致发送方和接收方都发生数据复制。这是保持界面易于使用与提供可靠性之间的权衡。理想情况下，通过网络传输数据时将避免所有内存副本。有一些技术和 API 可用于避免内存复制，但实际上，避免复制的成本通常可能超过复制本身，特别是对于小型传输（以字节为单位，而不是千字节或更多）。

为了避免发送方的内存复制，我们需要将应用程序数据直接放置到网络上。如果我们还想避免阻塞发送应用程序，那么当缓冲区可以安全地重用时，我们需要某种方式让网络层与应用程序进行通信。这将允许在需要重新传输数据的情况下重新使用原始缓冲区。这导致我们设计一个异步行为的网络接口。应用程序需要发出请求，然后在请求完成时收到某种通知。

避免接收器处的内存复制更具挑战性。当数据从网络到达时，它需要降落到可用的内存缓冲区中，否则它将被丢弃，导致发送方重新传输数据。如果我们使用套接字的recv()语义，避免在接收方进行复制的唯一方法是在send()之前调用recv()。Recv() 将需要阻塞，直到数据到达。这不仅会阻塞接收器，而且在应用程序外部使用简单的请求-应答协议也是不切实际的。

相反，接收应用程序需要一种方法来向网络提供一个或多个缓冲区，以便接收到的数据到达。然后，网络需要在数据可用时通知应用程序。如果接收方不关心数据位于其内存空间中的哪个位置，这种机制就可以很好地工作。它只需要能够处理传入的消息。

作为替代方案，可以反转此流程，并使网络层将其缓冲区移交给应用程序。然后，应用程序在完成处理后负责将缓冲区返回到网络层。虽然这种方法可以避免内存复制，但它也有一些缺点。首先，网络层不知道期望的消息大小，这可能导致内存使用效率低下。其次，许多人会认为这是一个更难使用的编程模型。最后，网络缓冲区需要映射到应用程序进程的内存空间，这会对性能产生负面影响。

除了处理消息之外，一些应用程序还希望接收数据并将其存储在内存中的特定位置。例如，数据库可能希望将接收到的数据记录合并到现有表中。在这种情况下，即使从网络到达的数据直接进入应用程序的接收缓冲区，它可能仍然需要复制到其最终位置。如果网络支持将从网络到达的数据放置到特定的内存缓冲区中，并且根据数据的内容确定缓冲区，那将是理想的。

### 网络缓冲区

基于上述问题，我们可以开始看到避免内存复制取决于用于网络流量的内存缓冲区的所有权。对于基于套接字的传输，网络缓冲区由网络堆栈拥有和管理。这通常由操作系统内核处理。然而，这会导致数据在应用程序缓冲区和网络缓冲区之间“反弹”。通过让应用程序控制管理网络缓冲区，我们可以避免这种开销。这样做的代价是增加应用程序的复杂性。

请注意，即使我们希望应用程序拥有网络缓冲区，我们仍然希望避免应用程序实现复杂网络协议的情况。权衡是应用程序向网络堆栈提供数据缓冲区，但网络堆栈继续处理流量控制、可靠性以及分段和重组等事务。

### 资源管理

我们将资源管理定义为正确分配网络资源，以避免数据缓冲区或队列溢出。流量控制是资源管理的一个常见方面。如果没有适当的流量控制，发送方可能会超出缓慢或繁忙的接收方。这可能会导致数据包丢失、重新传输以及网络拥塞加剧。在实现流量控制算法方面已经进行了大量的研究和开发。由于其复杂性，应用程序开发人员不需要处理它。也就是说，在某些应用程序中，流量控制根本不属于网络协议。例如，请求-应答协议自然具有内置的流量控制。

出于我们的目的，我们将资源管理的定义扩展到流量控制之外。流量控制通常只处理对等方的可用网络缓冲。我们还希望关注出站数据传输队列中的可用空间。也就是说，当我们向本地 NIC 发出命令来发送数据时，这些命令可以在 NIC 处排队。当我们考虑可靠性时，这意味着跟踪未完成的请求，直到它们得到确认。资源管理需要确保我们不会溢出该请求队列。

此外，支持异步操作（下面详细描述）将引入潜在的新队列。这些队列也不得溢出。

## 异步操作

可以说，实现高性能的关键特征是支持异步操作，或者重叠不同通信以及通信与计算的能力。套接字 API 支持非阻塞模式的异步传输。但是，由于 API 本身是同步操作的，因此会产生额外的数据副本。对于异步 API，应用程序需要能够提交工作，然后收到某种工作已完成的通知。为了避免额外的内存复制，应用程序必须同意在操作完成之前不修改其数据缓冲区。

有两种主要方法可以通知应用程序可以安全地重用其数据缓冲区。一种机制是网络层调用某种回调或向应用程序发送请求已完成的信号。一些异步 API 使用此机制。这种方法的缺点是信号会中断应用程序的处理。这会对 CPU 缓存产生负面影响，并且需要中断处理。此外，开发能够处理随时发生的信号的应用程序通常很困难。

支持异步操作的另一种机制是在操作完成时将事件写入某种完成队列中。这提供了一种向应用程序指示数据传输何时完成的方法，并让应用程序可以控制何时以及如何处理已完成的请求。例如，它可以批量处理请求，以提高代码局部性和性能。

### 中断和信号

中断是支持异步操作的自然扩展。但是，在处理异步 API 时，它们可能会对性能产生负面影响。中断，即使定向到内核代理，也可能干扰应用程序处理。

如果应用程序具有异步接口，并将已完成的操作写入完成队列，则应用程序通常只需检查队列中的事件就足够了。只要应用程序有其他工作要执行，就不需要阻塞。这减少了对中断生成的需要。NIC 只需要向完成队列中写入一个条目并更新尾指针以表明请求已完成。

如果我们遵循这个论点，那么让应用程序控制何时应该发生中断以及何时将事件写入某种等待对象可能是有益的。通过让应用程序通知网络层它将等待完成，我们可以更好地管理生成的中断的数量和类型。

### 事件队列

如上所述，使用事件队列报告完成情况或提供其他类型通知的 API 具有性能优势。一种非常简单的事件队列类型仅跟踪已完成的操作。当数据被接收或发送完成时，一个条目被写入事件队列。

## 直接硬件访问

在讨论网络层时，大多数软件实现都是指负责实现必要的传输和网络协议的内核模块。但是，如果我们希望网络延迟接近亚微秒速度，那么我们需要在应用程序及其对硬件的访问之间删除尽可能多的软件。实现此目的的一种方法是应用程序可以直接访问网络接口控制器的命令队列。类似地，NIC需要直接访问应用程序的数据缓冲区和控制结构，例如上面提到的完成队列。

请注意，当我们谈论可以直接访问网络硬件的应用程序时，我们指的是应用程序进程。当然，应用程序开发人员不太可能为特定的硬件 NIC 进行编码。这项工作将留给某种专门针对 NIC 的网络库。实现网络传输的实际网络层可以是网络库的一部分，也可以卸载到 NIC 的硬件或固件上。

### 内核绕过

内核旁路是一项允许应用程序避免调用内核进行数据传输操作的功能。当它可以直接访问 NIC 硬件时，这是可能的。由于安全问题和资源管理限制，完全绕过内核是不切实际的。但是，可以避免内核调用所谓的“快速路径”操作，例如发送或接收。

出于安全和稳定性原因，操作系统内核不能依赖来自用户空间应用程序的数据。因此，即使是简单的内核调用也常常需要获取和释放锁，以及数据验证检查。如果我们能够将编写不当或恶意应用程序的影响限制在其自己的进程空间中，我们就可以避免内核验证带来的开销，而不会影响系统稳定性。

### 直接数据放置

直接数据放置意味着在发送和接收数据时避免数据复制，并且在需要时将接收到的数据放置到正确的内存缓冲区中。从更广泛的角度来看，它是直接硬件访问的一部分，应用程序和 NIC 直接与共享内存缓冲区和队列进行通信。

熟悉 RDMA（远程直接内存访问）的人通常会想到直接数据放置。RDMA 是一种允许读取和写入属于网络节点上运行的对等进程的内存的技术。高级 RDMA 硬件能够访问目标内存缓冲区，而无需执行对等进程。RDMA 依赖于将网络传输卸载到 NIC 上以避免中断目标进程。

支持直接数据放置的主要优点是避免内存复制并最大限度地减少处理开销。

# 设计界面以提高性能

我们想要设计一个能够满足上述要求的网络接口。而且，我们还要考虑到界面本身的性能。接口如何对性能产生不利影响通常并不明显，而性能是底层实现的结果。以下部分描述了接口选择如何影响性能。当然，当我们开始定义应用程序将使用的实际 API 时，我们需要牺牲原始性能以换取有意义的易用性。

在考虑 API 的性能目标时，我们需要考虑目标应用程序用例。出于本次讨论的目的，我们希望考虑与数千到数百万个对等进程进行通信的应用程序。数据传输将包括每个对等点每秒数百万条小消息，以及可能高达千兆字节的数据传输。在如此极端的规模下，即使是很小的优化，在性能和功耗方面也是可以衡量的。如果我们有一百万个对等点每秒发送数百万条消息，那么在查看整个应用程序的操作时，即使从代码路径中消除一条指令，也会快速成倍地每秒从整体执行中节省数十亿条指令。

我们在本次讨论中再次提到套接字 API，以说明 API 如何影响性能。

```
/* Notable socket function prototypes */
/* "control" functions */
int socket(int domain, int type, int protocol);
int bind(int socket, const struct sockaddr *addr, socklen_t addrlen);
int listen(int socket, int backlog);
int accept(int socket, struct sockaddr *addr, socklen_t *addrlen);
int connect(int socket, const struct sockaddr *addr, socklen_t addrlen);
int shutdown(int socket, int how);
int close(int socket);

/* "fast path" data operations - send only (receive calls not shown) */
ssize_t send(int socket, const void *buf, size_t len, int flags);
ssize_t sendto(int socket, const void *buf, size_t len, int flags,
    const struct sockaddr *dest_addr, socklen_t addrlen);
ssize_t sendmsg(int socket, const struct msghdr *msg, int flags);
ssize_t write(int socket, const void *buf, size_t count);
ssize_t writev(int socket, const struct iovec *iov, int iovcnt);

/* "indirect" data operations */
int poll(struct pollfd *fds, nfds_t nfds, int timeout);
int select(int nfds, fd_set *readfds, fd_set *writefds,
    fd_set *exceptfds, struct timeval *timeout);
```

检查这个列表，有几个特点需要注意。首先，有多个调用可用于发送数据，以及多个调用可用于等待非阻塞套接字准备就绪。稍后将对此进行更详细的讨论。其次，操作已分为不同的组（术语是我们的）。控制操作是应用程序在执行过程中很少调用的函数。它们通常仅作为初始化的一部分出现。

另一方面，数据操作在应用程序的生命周期内可能被调用数百到数百万次。它们直接或间接地通过网络传输或接收数据。数据操作可以分为两组。快速路径调用与网络堆栈交互以立即发送或接收数据。为了实现高带宽和低延迟，这些操作需要尽可能快。仍处理数据传输的非快速路径操作是那些虽然仍被应用程序频繁调用但性能不那么关键的调用。例如，select() 和 poll() 调用用于阻塞应用程序线程，直到套接字准备就绪。由于这些调用会挂起线程执行，因此性能不太受关注。（这些操作的性能仍然令人担忧，

## 呼叫建立费用

应用程序在发出数据传输操作之前需要执行的工作量可能会影响性能，尤其是消息速率。显然，应用程序调用函数时必须压入堆栈的参数越多，其指令数就越多。然而，用单个数据结构替换堆栈变量无助于降低设置成本。

假设应用程序希望向对等方发送给定大小的单个数据缓冲区。如果我们检查套接字 API，最适合此类操作的是 write() 调用。该调用仅采用执行数据传输所需的那些值。send() 调用紧随其后，send() 是一种更自然的网络通信函数名称，但 send() 比 write() 需要一个额外的参数。其他功能在设置成本方面甚至更差。例如，sendmsg() 函数要求应用程序格式化一个数据结构，并将其地址传递到调用中。如果每次数据传输都执行此操作，则需要应用程序发出更多指令。

尽管所有其他发送函数都可以用 sendmsg() 替换，但应用程序通过多种方式发出发送请求还是很有用的。其他调用不仅更易于阅读和使用（这降低了软件维护成本），而且还可以提高性能。

## 分支和循环

在设计 API 时，开发人员很少考虑 API 如何影响底层实现。然而，API 参数的选择可能要求底层实现添加分支或使用控制循环。考虑 write() 和 writev() 调用之间的区别。后者传入一个 I/O 向量数组，可以使用如下循环进行处理：

```
/* Sample implementation for processing an array */
for (i = 0; i < iovcnt; i++) {
    ...
}
```

为了处理 iovec 数组，自然的软件构造将使用循环来迭代条目。循环会导致额外的处理。通常，循环需要初始化循环控制变量（例如 i = 0）、添加 ALU 操作（例如 i++）和比较（例如 i < iovcnt）。此开销对于处理任意数量的 iovec 条目是必要的。如果常见情况是应用程序想要发送单个数据缓冲区，则 write() 是更好的选择。

除了控制循环之外，API 还可能导致需要分支的实现。分支可以改变程序的执行流程，影响处理器的管道技术。处理器分支预测有助于缓解这个问题。然而，虽然在运行微基准（例如网络带宽或延迟测试）时分支预测几乎 100% 正确，但随着网络流量更加真实，其影响是可以衡量的。

如果我们检查 send() 调用，我们可以很容易地看到 API 如何在代码流中引入分支。Send() 比 write() 调用需要一个额外的标志参数。这允许应用程序修改 send() 的行为。从实现 send() 的角度来看，必须检查 flags 参数。在最好的情况下，这会添加一项额外的检查（标志非零）。在最坏的情况下，每个有效标志可能需要单独检查，从而可能导致数十次检查。

总的来说，套接字 API 的设计考虑到了这些性能影响。它在需要时提供复杂的调用，并提供更简单的函数，可以避免其他调用中固有的一些开销。

## 命令格式

调用网络功能的最终目的是从网络传输或接收数据。在本节中，我们将深入到软件堆栈的最底部，直到负责直接访问硬件的组件。这通常称为网络驱动程序，其实现通常与特定硬件或单个硬件供应商的一系列 NIC 相关联。

为了通知 NIC 应读取内存缓冲区并将数据复制到网络上，软件驱动程序通常需要向 NIC 写入某种命令。为了限制硬件复杂性和成本，NIC 可能仅支持几种命令格式。这与我们一直在讨论的软件接口不同，在软件接口中，我们可以使用不同复杂性的不同 API，以减少开销。格式化命令并将其发布到硬件可能会产生巨大的成本。

对于标准 NIC，该命令由内核驱动程序格式化。该驱动程序位于网络堆栈的底部，为来自多个应用程序的请求提供服务。通常，只有在请求通过网络堆栈后，它才必须格式化每个命令。

对于可由单个应用程序直接访问的设备，有机会使用预先格式化的命令结构。在应用程序提交网络请求之前可以初始化的命令越多，流程就越简化，性能就越好。

例如，NIC 需要将目标地址作为发送操作的一部分。如果应用程序发送到单个对等点，则该信息可以被缓存并成为预格式化网络标头的一部分。仅当 NIC 驱动程序知道目标在发送之间不会更改时，这才有可能。驱动程序与应用程序越接近，优化的机会就越大。最佳方法是让驱动程序成为完全在应用程序进程空间内执行的库的一部分。

## 内存占用

在与数千个对等点通信的高性能计算 (HPC) 应用程序中，内存占用问题最为显着。过多的内存消耗会影响应用程序的可扩展性，限制可以并行操作来解决问题的对等点的数量。在最小化网络通信所需的内存占用、应用程序性能和网络接口的易用性之间通常需要进行权衡。

正如我们讨论的套接字 API 语义一样，使用套接字的部分便利性来自于网络分层将用户的缓冲区复制到属于网络堆栈的内部缓冲区。可供应用程序使用的内部缓冲量与应用程序可以获得的带宽直接相关。一般来说，较大的内部缓冲可以提高网络性能，但代价是增加应用程序消耗的内存占用量。此内存占用量的存在与应用程序直接分配的内存量无关。消除网络缓冲不仅有助于提高性能，而且还可以通过减少支持应用程序所需的内存占用来提高可扩展性。

虽然网络内存缓冲随着应用程序的扩展而增加，但通常可以将其配置为固定大小。所需的缓冲量取决于任一时间使用的活动通信流的数量。该数字通常明显低于应用程序可能需要与之通信的对等点总数。*然而，对对等点进行寻址*所需的内存量通常与对等点总数呈线性关系。

对于套接字 API，每个对等点都使用 struct sockaddr 进行标识。如果我们考虑使用 IPv4 地址的基于 UDP 的套接字应用程序，则对等点由以下地址标识。

```
/* IPv4 socket address - with typedefs removed */
struct sockaddr_in {
    uint16_t sin_family; /* AF_INET */
    uint16_t sin_port;
    struct {
        uint32_t sin_addr;
    } in_addr;
};
```

总的来说，应用程序需要为每个对等点提供 8 个字节的寻址。如果应用程序与一百万个对等点进行通信，则仅用于维护地址列表就会消耗大约 8 MB 的内存空间。如果需要 IPv6 寻址，则要求会增加 4 倍。

幸运的是，有一些技巧可以用来帮助减少寻址内存占用，尽管这样做会在代码路径中引入更多指令来访问网络堆栈。例如，我们可以注意到上例中的所有地址都具有相同的 sin_family 值 (AF_INET)。无需为每个地址存储该信息。这可能会将每个地址从 8 个字节缩小到 6 个字节。（我们可能会留下未对齐的数据，但这是减少内存消耗的权衡）。根据地址的分配方式，可能会进一步减少。例如，如果应用程序在每个节点使用相同的端口地址集，那么我们可以消除存储端口，而是根据某个基值进行计算。

这种地址减少的主要问题是很难实现。它要求每个应用程序检查并处理地址压缩，从而将应用程序暴露给网络堆栈使用的寻址格式。应该记住，TCP/IP 和 UDP/IP 地址是逻辑地址，而不是物理地址。当通过以太网运行时，出现在链路层的地址是 MAC 地址，而不是 IP 地址。IP 到 MAC 地址的关联由网络软件管理。我们希望提供易于应用程序使用的寻址，但同时可以提供最小的内存占用。

## 通讯资源

我们需要在讨论中绕一小段路，以便更深入地研究网络问题和解决方案空间。我们不想继续将套接字视为具有发送和接收功能的单个实体，而是要单独考虑其组件。网络套接字可以被视为三个基本结构：传输层地址、发送或传输队列以及接收队列。因为我们的讨论将开始偏离纯套接字语义，所以我们将网络“套接字”称为端点。

为了减少应用程序的内存占用，我们需要考虑套接字 API 之外的功能。到目前为止，大部分讨论都是围绕向对等方发送数据进行的。我们现在希望关注接收数据的最佳机制。

对于套接字，当应用程序有数据要接收时（例如，通过 POLLIN 事件指示），我们调用 recv()。网络堆栈将接收数据复制到其缓冲区中并返回。*如果我们想避免接收端的数据复制，我们需要一种方法让应用程序在数据到达之前*将其缓冲区发布到网络堆栈。

可以说，扩展套接字 API 以支持此功能的自然方法是让每次调用 receive() 简单地将缓冲区发送到网络层。当接收到数据时，接收缓冲区将按照它们发布的顺序被删除。数据被复制到发布缓冲区中并返回给用户。应当注意，发布的接收缓冲器的大小可以大于（或小于）接收的数据量。假设，如果可用缓冲区空间较大，网络层可以等待较短的时间以查看是否有更多数据到达。如果没有更多信息到达，则接收完成并将缓冲区返回给应用程序。

这就提出了一个关于如何处理接收端缓冲的问题。到目前为止，对于套接字，我们主要考虑的是流协议。然而，许多应用程序处理的消息最终会分层在数据流上。如果他们发送 8 KB 消息，他们希望接收者收到 8 KB 消息。需要维护消息边界。

如果应用程序发送和接收固定大小的消息，则缓冲区分配变得微不足道。该应用程序可以发布 X 个缓冲区，每个缓冲区都有最佳大小。然而，如果消息大小混合广泛，就会出现困难。对于应用程序来说，80% 的消息为几百字节或更少，但其发送的总数据的 80% 是在大型传输中（例如 1 MB 或更多），这种情况并不罕见。在这种情况下预发布接收缓冲区是具有挑战性的。

处理这种情况的常用技术是为较小的消息实现一个应用程序级协议，并为大于某个给定阈值的传输使用单独的协议。这将允许应用程序发布一堆较小的消息（例如 4 KB）来接收数据。对于大于 4 KB 的传输，可能会通过不同的套接字或端点使用不同的通信协议。

### 共享接收队列

如果应用程序将接收缓冲区预先发布到网络队列，则需要平衡发布的每个缓冲区的大小、发布到每个队列的缓冲区数量以及正在使用的队列数量。使用类似套接字的方法，每个套接字将维护一个独立的接收队列，用于放置数据。如果应用程序使用 1000 个端点并发布 100 个缓冲区（每个缓冲区 4 KB），则将消耗 400 MB 的内存空间来接收数据。（我们可以开始意识到，通过消除内存副本，权衡之一是增加内存消耗。）虽然 400 MB 看起来很大，但分配给单个接收队列的内存还不到半兆字节。以当今的网络速度，这些空间可以在几毫秒内被消耗掉。结果是，如果只使用几个端点，

我们可以在这里做出一些观察。首先，为了实现高可扩展性，我们需要放弃面向连接的协议，例如流式套接字。其次，我们需要减少应用程序使用的接收队列的数量。

共享接收队列是可以同时接收许多不同端点的数据的网络队列。通过共享接收队列，我们不再将接收队列与特定的传输地址相关联。相反，网络数据将针对特定的端点地址。当数据到达时，端点将从共享接收队列中删除一个条目，将数据放入应用程序的发布缓冲区中，然后将其返回给用户。共享接收队列可以大大减少应用程序所需的缓冲区空间量。在前面的示例中，如果使用共享接收队列，应用程序可以发布 10 倍数量的缓冲区（总共 1000 个），但消耗的内存仍然减少 100 倍（总共 4 MB）。这更具可扩展性。缺点是应用程序现在必须了解接收队列和共享接收队列，

### 多接收缓冲器

共享接收队列大大提高了应用程序的可扩展性；然而，按照目前的定义，它仍然会导致一些低效率的情况。我们只考虑了将一系列固定大小的内存缓冲区发送到接收队列的情况。如前所述，确定每个缓冲区的大小具有挑战性。大于固定大小的传输需要使用其他协议才能完成。如果传输通常远小于固定大小，则额外的缓冲区空间将不会被使用。

再次参考我们的示例，如果应用程序发布 1000 个缓冲区，那么在队列清空之前它只能接收 1000 条消息。以每秒数百万条消息测量的数据速率，这将导致数据流停顿。一个明显的解决方案是增加发布的缓冲区数量。问题在于处理可变大小的消息，包括一些长度只有几百字节的消息。例如，如果我们的例子中的平均消息大小为 256 字节或更小，那么即使我们分配了 4 MB 的缓冲区空间，我们也只使用了该空间的 6%。其余的则被浪费在处理消息上，而消息可能偶尔会达到 4 KB。

我们可以进行的第二个优化是在消息到达时填充每个发布的接收缓冲区。因此，它不会在单个 256 字节消息到达后立即停止使用 4 KB 缓冲区，而是可以接收最多 16 个 256 字节消息。我们将这种功能称为“多接收”缓冲区。

对于多接收缓冲区，我们不是发布一堆较小的缓冲区，而是一次发布一个较大的缓冲区，例如整个 4 MB。接收到数据后，将其放入发布缓冲区中。与 TCP 流不同，我们仍然维护消息边界。这里的优点是双重的。不仅可以更有效地使用内存，使我们能够一次接收更多较小的消息和整体上更大的消息，而且我们还减少了应用程序为维持可用接收缓冲区的供应而必须进行的函数调用数量。

与共享接收队列结合使用时，多接收缓冲区有助于支持最佳接收端缓冲和处理。支持多接收缓冲区的主要缺点是应用程序不一定预先知道有多少消息可能与单个发布的内存缓冲区关联。这对于应用程序来说很少是一个问题。

## 最佳硬件配置

作为可扩展性考虑的一部分，我们不仅需要考虑主机系统的处理和内存资源，还需要考虑NIC硬件的分配和使用。我们将网络端点称为传输寻址、传输队列和接收队列的组合。后两个队列通常被实现为硬件命令队列。命令队列用于向 NIC 发出信号以执行某种工作。传输队列指示 NIC 应传输数据。发送命令通常包含要发送的缓冲区的地址、缓冲区的长度和目标寻址数据等信息。实际格式和数据内容因硬件实现而异。

NIC 的资源有限。只有最具可扩展性、高性能的应用程序才可能需要考虑如何最佳地利用 NIC 硬件。然而，此类应用程序是 libfabric 的一个重要且特定的焦点。管理 NIC 资源通常由资源管理器应用程序处理，该应用程序负责将系统分配给竞争应用程序以及其他活动。

支持希望充分利用硬件的应用程序需要将与硬件相关的抽象暴露给应用程序。这种抽象不需要特定的硬件实现，并且必须注意确保不熟悉处理此类低级细节的开发人员仍然可以使用生成的 API。公开共享接收队列等概念是让应用程序更好地控制硬件资源使用方式的一个示例。

### 共享命令队列

通过向应用程序公开传输和接收队列，我们为应用程序提供了利用多个端点来确定如何共享这些队列的可能性。我们讨论了在端点之间共享接收队列的好处。共享传输队列的好处并不那么明显。

使用比传输队列更多的可寻址端点的应用程序将需要在端点之间共享传输队列。通过控制哪个端点使用哪个传输队列，应用程序可以确定流量的优先级。传输队列还可以配置为针对特定类型的数据传输进行优化，例如仅针对大型传输。

从软件 API 的角度来看，共享传输或接收队列意味着将这些构造暴露给应用程序，并允许它们与不同的端点地址关联。

### 多个队列

与共享命令队列相反的是具有多个队列的端点。可以利用多个传输或接收队列的应用程序可以增加消息的并行处理，而无需同步约束。能够通过单个端点使用多个命令队列比使用多个端点具有优势。多个端点需要单独的地址，这会增加内存使用量。具有多个队列的单个端点可以继续公开单个地址，同时充分利用可用的 NIC 资源。

## 进度模型注意事项

开发人员经常不考虑套接字编程接口的一方面是协议实现的位置。这通常由操作系统内核管理。网络堆栈负责处理流量控制消息、超时传输、重新传输未确认的传输、处理接收到的数据以及发送确认。此处理需要网络堆栈消耗 CPU 周期。该处理的一部分可以在应用程序线程的上下文中完成，但大部分必须由专用于网络处理的内核线程来处理。

通过将网络处理直接移至应用程序进程中，我们需要关心网络通信如何向前推进。例如，如何以及何时发送确认？如何处理超时和消息重传？进度模型定义了此行为，它取决于已卸载到 NIC 上的网络处理量。

更一般地说，进度是底层网络实现完成异步请求处理的能力。在许多情况下，异步请求的处理需要使用主机处理器。出于性能原因，提供程序可能不希望为此目的分配线程，因为这将与应用程序线程竞争。如果应用程序线程可用于在请求上取得进展（检查确认、重试超时操作等），我们就可以避免线程上下文切换。这样做需要应用程序定期调用网络堆栈。

## 订购

网络订购是一个复杂的主题。对于 TCP 套接字，数据以相同的顺序发送和接收。从函数调用返回后，应用程序可以立即重用缓冲区。因此，订购很容易理解和使用。UDP 套接字使事情稍微复杂化。使用 UDP 套接字时，接收消息的顺序可能与发送消息的顺序不一样。实际上，这种情况通常不会发生，特别是当应用程序仅通过局域网（例如以太网）进行通信时。

随着我们不断发展的网络 API，在某些情况下公开不同的顺序语义可以提高性能。这些细节将在下面进一步讨论。

### 留言

UDP 套接字允许消息无序到达，因为每条消息都是独立地从发送方路由到接收方。这允许数据包采用不同的网络路径，以避免拥塞或利用多个网络链路来提高带宽。在应用程序不关心消息到达顺序的情况下，我们希望利用相同的功能。

然而，与 UDP 套接字不同，我们对消息排序的定义更加微妙。UDP 消息是 MTU 大小的小型数据包。在我们的例子中，消息的大小可能是千兆字节。我们定义消息排序来指示每条消息的开头是按顺序还是无序处理。这与消息有效负载的接收顺序相关，但又相互独立。

一个例子将有助于阐明这种区别。假设应用程序已将两条消息发布到其接收队列。第一个接收指向 4 KB 缓冲区。第二个接收指向 64 KB 缓冲区。发送方将传输一条 4 KB 消息，然后传输一条 64 KB 消息。如果按顺序处理消息，则 4 KB 发送将与 4 KB 接收匹配，64 KB 发送将与 64 KB 接收匹配。但是，如果消息可以乱序处理，则发送和接收可能会不匹配，从而导致 64 KB 发送被截断。

在此示例中，我们不关心数据接收的顺序。64 KB 发送可能会在 64 个 1 KB 传输中被破坏，这些传输采用不同的路由到达目的地。因此，字节 2k-3k 可以在字节 1k-2k 之前接收。消息排序与消息*内的*排序无关，只涉及消息*之间的*排序。对于有序消息，消息本身需要按顺序处理。

消息排序越宽松，网络堆栈可用于传输数据的优化就越多。但是，应用程序必须了解消息排序语义，并且能够根据需要选择所需的语义。就本节而言，消息是指传输级操作，其中包括 RDMA 和类似操作（其中一些尚未讨论）。

### 数据

*数据排序是指消息内和消息之间*数据的接收和放置 。数据排序对于可以更新同一目标内存缓冲区的消息来说最为重要。例如，想象一个应用程序将一系列数据库记录直接写入对等内存位置。数据排序与消息排序相结合，可确保第二次写入的数据在第一次写入完成后更新内存。结果是该内存位置将包含第二次写入中携带的记录。

在消息之间强制执行数据排序需要对消息本身进行排序。数据排序也可以应用于单个消息中，尽管这种级别的排序通常对应用程序不太重要。消息内数据排序指示单个消息的数据按顺序接收。一些应用程序使用此功能来“旋转”读取接收缓冲区的最后一个字节。一旦字节发生变化，应用程序就知道操作已完成并且所有早期数据均已收到。（请注意，虽然这种行为对于基准测试而言很有趣，但强烈建议不要以这种方式使用此类功能。它不可在网络或平台之间移植。）

### 竣工数量

完成顺序是指异步操作向应用程序报告其完成情况的顺序。通常，不可靠的数据传输自然会按照它们提交到传输队列的顺序完成。每个操作都会传输到网络，然后立即完成。对于可靠的数据传输，操作只有在得到对等方确认后才能完成。由于 ack 数据包可能会丢失或可能采用不同的网络路径，因此操作可能会被标记为已无序完成。如果消息可以乱序处理，那么乱序确认的可能性就更大。

异步接口要求应用程序跟踪其未完成的请求。处理无序完成会增加应用程序的复杂性，但它确实可以优化网络利用率。

# 图书馆架构

Libfabric 的架构良好，可以支持前面讨论的功能。有关 libfabric 架构的更多信息，请参阅下一个程序员指南部分：[`fi_arch`(7)](https://ofiwg.github.io/libfabric/main/man/fi_arch.7.html)。

------

[© 2023 OpenFabrics 接口工作组在Jekyll Bootstrap](http://jekyllbootstrap.com/) 和[Twitter Bootstrap](http://twitter.github.com/bootstrap/)的帮助下







# fi_arch(7) Libfabric 程序员指南 - 架构

# 姓名

fi_arch - libfabric 架构

# 概述

Libfabric API 定义面向应用程序的通信语义，无需强制执行底层实现或有线协议。它的架构使得应用程序可以直接访问网络硬件而无需操作系统干预，但并不强制执行这样的实现。API 已专门定义为允许多种实现。

下图突出显示了 libfabric 公开的接口的总体架构。

```
                 Applications and Middleware
       [MPI]   [SHMEM]   [PGAS]   [Storage]   [Other]

--------------------- libfabric API ---------------------

/  Core  \ + /Communication\ + /  Data  \ + <Completion>
\Services/   \    Setup    /   \Transfer/

----------------- libfabric Provider API ----------------

                    libfabric providers
   [TCP]   [UDP]   [Verbs]    [EFA]    [SHM]   [Other]

---------------------------------------------------------

     Low-level network hardware and software interfaces
```

每个 libfabric 组件的详细信息如下所述。

## 核心服务

libfabric 可以分为 libfabric 核心和提供程序。核心定义了应用程序使用的 API 并实现了所谓的发现服务。发现服务负责识别系统中可用的硬件、平台功能、操作系统功能、关联的通信和计算库等。提供程序是 libfabric API 的优化实现。libfabric 核心的目标之一是将上层应用程序和中间件与最适合其需求的特定提供商联系起来。

从应用程序的角度来看，核心 libfabric 服务主要通过 fi_getinfo() API 访问。参见 [`fi_getinfo`(3)](https://ofiwg.github.io/libfabric/main/man/fi_getinfo.3.html)。

## 供应商

与许多库不同，libfabric 核心并未实现用户调用的大部分 API。相反，这个责任落到了 libfabric 所谓的提供者身上。libfabric API 的大部分由每个提供商实现。当应用程序调用 libfabric API 时，该函数调用将直接路由到特定的提供程序。这是使用与特定 libfabric 定义的对象关联的函数指针来完成的。下面更详细地描述对象模型。

这种方法的好处是每个提供商都可以根据其可用的网络硬件、操作系统、平台和网络协议功能来优化 libfabric 定义的通信语义。

一般来说，每个提供商都专注于通过特定的较低级别通信 API 或 NIC 支持 libfabric API。有关可用的不同类型的提供程序和提供程序架构的讨论，请参阅 [`fi_provider`(7) 。](https://ofiwg.github.io/libfabric/main/man/fi_provider.7.html)

## 通讯设置

在高层，通过 libfabric 的通信可以是面向连接的或无连接的。尽管 libfabric 支持可靠的无连接通信语义，但这类似于在使用 TCP 或 UDP 套接字之间进行选择。两个进程之间的通信通过称为端点的结构进行。从概念上讲，端点相当于套接字 API 世界中的套接字。

特定的 API 和 libfabric 对象旨在管理和设置节点之间的通信。它包括对连接管理 (CM) 的调用，以及用于寻址无连接端点的功能。

CM API 是根据用于连接 TCP 套接字的 API 建模的：connect()、bind()、listen() 和accept()。主要区别在于 libfabric 调用被设计为始终异步操作。[`fi_cm`CM API 在(3)](https://ofiwg.github.io/libfabric/main/man/fi_cm.3.html)中讨论。

[`fi_intro`出于(7)](https://ofiwg.github.io/libfabric/main/man/fi_intro.7.html)页中讨论的性能和可扩展性原因 ，无连接端点使用独特的模型来设置通信。它们基于称为地址向量的概念，其中术语向量表示表或数组。地址向量稍后详细讨论，但目标应用程序需要与潜在的数千到数百万对等点进行通信。

## 数据传输服务

libfabric 提供了多种数据传输语义来满足不同的应用程序需求。有五组基本的数据传输 API：消息、标记消息、RMA、原子和集合。

- *留言*

  消息 API 公开了发送和接收数据并维护消息边界的能力。消息传输充当 FIFO，发送的消息按照目标接收消息的顺序与接收缓冲区进行匹配。消息 API 是根据套接字 API 建模的，例如 send()。sendto()、sendmsg()、recv()、recvmsg() 等。有关详细信息，请参阅[`fi_msg`(3)](https://ofiwg.github.io/libfabric/main/man/fi_msg.3.html)。

- *已标记的消息*

  带标签的消息与消息 API 类似，但消息在接收方的匹配方式不同。带标签的消息维护消息边界，与消息 API 相同。标签匹配 API 与消息 API 的不同之处在于，接收到的消息根据发送消息中指定和携带的小引导标签定向到缓冲区中。所有用于发送或接收数据的消息缓冲区都与一个标记值相关联。发送的消息与接收方具有相同标签的缓冲区进行匹配。欲了解更多信息，请参阅 [`fi_tagged`(3)](https://ofiwg.github.io/libfabric/main/man/fi_tagged.3.html)。

- *退货授权*

  RMA 代表远程内存访问。RMA 传输允许应用程序将数据直接写入目标进程中的特定内存位置，或从目标进程中的特定地址读取内存并将数据返回到本地缓冲区。RMA也称为RDMA（远程直接内存访问）；然而，RDMA最初定义了RMA的特定传输实现。欲了解更多信息，请参阅 [`fi_rma`(3)](https://ofiwg.github.io/libfabric/main/man/fi_rma.3.html)。

- *原子学*

  原子操作将算术操作添加到 RMA 传输中。原子允许直接访问和操作目标进程上的内存。libfabric 定义了广泛的算术运算，可以作为数据传输操作的一部分进行调用。欲了解更多信息，请参阅[`fi_atomic`(3)](https://ofiwg.github.io/libfabric/main/man/fi_atomic.3.html)。

- *集体*

  上述数据传输API执行点对点通信。数据传输恰好发生在一个发起者和一个目标之间。集体操作是任意数量的对等点之间协调的原子操作。欲了解更多信息，请参阅 [`fi_collective`(3)](https://ofiwg.github.io/libfabric/main/man/fi_collective.3.html)。

## 记忆登记

libfabric 的目标之一是允许网络硬件直接访问应用程序数据缓冲区。这是通过称为内存注册的操作来完成的。

为了使 NIC 能够直接读取或写入应用程序内存，它必须访问支持应用程序地址空间的物理内存页。现代操作系统使用页面文件，将一个进程的虚拟页面与另一进程的虚拟页面交换。因此，物理内存页可能会根据访问时间映射到不同的虚拟地址。此外，当虚拟页被换入时，它可以被映射到新的物理页。如果 NIC 在未链接到虚拟地址管理器的情况下尝试读取或写入应用程序内存，则它可能会访问错误的数据，并可能损坏应用程序的内存。可以使用内存注册来避免这种情况的发生。例如，可以标记已注册的页面，以便操作系统锁定虚拟到物理的映射，

内存注册也是用于授予远程对等方访问本地内存缓冲区的安全机制。注册的内存区域将内存缓冲区与授予结构资源访问权限相关联。内存缓冲区必须先注册，然后才能用作 RMA 或原子数据传输的目标。内存注册提供了一种简单的保护机制。（高级可扩展网络采用其他机制，这些机制被认为超出了本次讨论的范围。）内存缓冲区注册后，该注册请求（缓冲区的地址、缓冲区长度和访问权限）将获得一个注册密钥。针对该内存缓冲区发出 RMA 或原子操作的对等方必须提供此密钥作为其操作的一部分。这有助于防止无意中访问该区域。

## 竣工服务

libfabric 数据传输异步运行。完成服务用于报告提交的数据传输操作的结果。可以使用巧妙命名的完成队列来报告完成情况，该队列提供有关已完成操作的详细信息。或者，可以使用仅返回已完成的操作数的完成计数器来报告完成情况。

完成服务的设计考虑到了高性能、低延迟。调用直接映射到提供程序，并且定义数据结构以最小化内存写入和缓存影响。完成服务没有相应的套接字API。然而，对于 Windows 开发人员来说，它们类似于 IO 完成端口。

# 对象模型

libfabric 遵循面向对象的设计模型。尽管接口是用 C 编写的，但其结构和实现具有 C++ 的感觉。下图显示了值得注意的 libfabric 对象和对象依赖关系的高级视图。

```
/ Passive \ ---> <Fabric> <--- /Event\
\Endpoints/         ^          \Queue/
                    |
  /Address\ ---> <Domain> <--- /Completion\
  \Vector /       ^  ^         \  Queue   /
                  |  |
      /Memory\ ---    --- / Active \
      \Region/            \Endpoint/
```

- *织物*

  结构表示访问单个物理或虚拟网络的硬件和软件资源的集合。例如，结构可以是单个网络子网或集群。系统上可以通过Fabric相互通信的所有网络端口都属于同一个Fabric。结构共享网络地址并且可以跨越多个提供商。结构是分配其他对象的顶级对象。

- *领域*

  域代表结构中的逻辑连接。最简单的情况下，一个域可能对应一个物理或虚拟的网卡；然而，一个域可以包含多个 NIC（在多轨提供商的情况下），或者根本没有 NIC（在共享内存的情况下）。域定义了其他资源可以关联的边界。活动端点和完成队列必须属于同一域才能相互关联。

- *被动端点*

  面向连接的协议使用被动端点来侦听传入的连接请求。被动端点通常映射到软件构造，并且可能跨越多个域。它们最好由监听套接字来代表。

- *事件队列*

  事件队列 (EQ) 用于收集和报告异步操作和事件的完成情况。事件队列处理*控制*事件，即与数据传输操作不直接关联的操作。将控制事件与数据传输事件分开的原因是出于性能原因。事件队列通常完全使用操作系统结构在软件中实现。控制事件通常发生在应用程序的初始化阶段，或者发生率比数据传输事件小几个数量级。面向连接的协议最常使用事件队列来通知连接请求或已建立的事件。

- *活动端点*

  活动端点是数据传输通信门户。它们在概念上类似于 TCP 或 UDP 套接字。活动端点用于执行数据传输。活动端点实现网络协议。

- *完成队列*

  完成队列 (CQ) 是用于报告数据传输操作完成情况的高性能队列。与事件队列不同，完成队列通常完全或部分在硬件中实现。完成队列接口旨在最大限度地减少软件开销。

- *内存区域*

  内存区域描述应用程序的本地内存缓冲区。为了使结构资源访问应用程序内存，应用程序必须首先通过构造内存区域向结构提供者授予权限。特定类型的数据传输操作（例如 RMA 和原子操作）需要内存区域。

- *地址向量*

  地址向量由无连接端点使用。它们将更高级别的地址（例如 IP 地址或主机名）映射到结构特定地址，这些地址对于应用程序来说可能更自然。地址向量的使用使提供商能够减少维护大型地址查找表所需的内存量，并消除数据传输操作期间昂贵的地址解析和查找方法。

# 沟通模式

端点代表通信入口，所有数据传输操作均在端点上发起。libfabric 定义了端点如何向应用程序公开的概念模型。它支持三种主要的通信端点类型。端点名称是从套接字 API 命名借用的。

- *FI_EP_MSG*

  可靠连接

- *FI_EP_DGRAM*

  不可靠的数据报

- *FI_EP_RDM*

  可靠-未连接

通信设置基于端点是连接还是未连接。可靠性是端点数据传输协议的一项功能。

## 互联通讯

下图突出显示了面向连接的通信背后的一般用法。连接通信基于用于连接 TCP 套接字的流，并具有改进的异步支持。

```
         1 listen()              2 connect()
             |                      |
         /Passive \  <---(3)--- / Active \
         \Endpoint/             \Endpoint/
         /                               \
        / (4 CONNREQ)                     \
/Event\                                     /Event\
\Queue/                                     \Queue/
                                           /
         5 accept()         (8 CONNECTED) /
             |                           /
         / Active \  ------(6)--------->
         \Endpoint/  <-----(7)----------
         /
        / (9 CONNECTED)
/Event\
\Queue/
```

连接需要使用被动和主动端点。为了建立连接，应用程序必须首先创建被动端点并将其与事件队列关联。事件队列将用于报告连接管理事件。然后应用程序调用被动端点上的监听。单个无源端点可用于形成多个连接。

连接对等体分配一个活动端点，该端点也与事件队列关联。在主动端点上调用 Connect，这会导致向被动端点发送连接请求 (CONNREQ) 消息。CONNREQ 事件被插入到被动端点的事件队列中，侦听应用程序可以在其中处理它。

处理 CONNREQ 后，侦听应用程序将分配一个活动端点以用于连接。活动端点与事件队列绑定。尽管该图显示了单独事件队列的使用，但主动端点可以使用与被动端点所使用的相同的事件队列。在活动端点上调用 Accept 以完成连接的形成。应该注意的是，OFI 接受调用与套接字使用的接受调用不同。差异是由于 OFI 支持进程直接 I/O 造成的。

libfabric 没有定义连接建立协议，但支持许多技术使用的传统三向握手。调用接受后，响应将发送到连接的活动端点。该响应在远程事件队列上生成 CONNECTED 事件。如果使用三向握手，远程端点将生成一条确认消息，该消息将为接受端点生成 CONNECTED 事件。无论连接协议如何，连接的主动方和被动方都将收到 CONNECTED 事件，表明连接已建立。

## 无连接通信

无连接通信允许活动端点之间进行数据传输，而无需经过连接设置过程。下图显示了设置无连接通信所需的基本组件。无连接通信设置与 UDP 套接字不同，它要求使用 libfabric 存储远程地址。

```
  1 insert_addr()              2 send()
         |                        |
     /Address\ <--3 lookup--> / Active \
     \Vector /                \Endpoint/
```

libfabric 要求将对等端点的地址插入到本地寻址表或地址向量中，然后才能针对远程端点启动数据传输。地址向量抽象了结构特定的寻址要求，并在需要地址解析时避免数据传输的长时间排队延迟。例如，IP 地址可能需要解析为以太网 MAC 地址。地址向量允许在应用程序初始化期间进行此解析。libfabric 没有定义地址向量的实现方式，仅定义了其概念模型。

所有传输数据的无连接端点都必须与地址向量相关联。

# 端点

在低级别，端点通常与传输上下文或队列和接收上下文或队列相关联。尽管术语传输和接收队列更容易理解，但 libfabric 使用术语上下文，因为不能保证充当 FIFO（先进先出）的队列行为。发送和接收上下文可以使用直接映射到进程地址空间的硬件队列来实现。端点可以配置为仅传输或接收数据。数据传输请求由底层提供者转换为插入到硬件传输和/或接收上下文中的命令。

端点也与完成队列相关联。完成队列用于报告异步数据传输操作的完成情况。

## 共享上下文

高级使用模型允许在多个端点之间共享资源。最常见的共享形式是让多个连接的端点使用单个接收上下文。这可以减少接收端缓冲要求，从而允许应用程序可以管理的连接端点的数量扩展到更大的数量。

# 数据传输

显然，网络通信的主要目标是在不同系统上运行的进程之间传输数据。与套接字 API 为 TCP 与 UDP 套接字定义不同的数据传输语义（即流与数据报消息）类似，libfabric 定义了不同类型的数据传输。然而，与套接字不同的是，libfabric 允许在单个端点上使用不同的语义，即使在与同一对等点通信时也是如此。

libfabric 对不同的数据传输语义使用单独的 API 集；不过，API 集之间有很强的相似性。差异是调用每种类型的数据传输所需的参数造成的。

## 消息传输

消息传输与 UDP 数据报传输最相似，只是传输可以可靠地发送和接收。消息传输的大小也可能是千兆字节，具体取决于提供程序的实现。发送方请求将数据作为单个传输操作传输到对等方。即使使用 I/O 向量引用数据，它也会被视为单个逻辑单元或消息。数据被放入对等方的等待接收缓冲区中，通常使用 FIFO 排序来选择接收缓冲区。请注意，即使使用 FIFO 排序选择接收缓冲区，接收到的消息也可能会乱序完成。这可能是由于消息之间和消息内的数据在网络中采用不同路径、处理丢失或重传的数据包等而发生的。

消息传输通常使用包含字符串“send”或“recv”的 API 调用来调用。因此，它们可以简称为发送或接收的消息。

消息传输涉及目标进程将内存缓冲区发布到其端点的接收 (Rx) 上下文。当消息从网络到达时，接收缓冲区将从 Rx 上下文中删除，并将数据从网络复制到接收缓冲区。消息按照接收顺序与发布的接收进行匹配。请注意，这可能与消息发送的顺序不同，具体取决于发送方的排序语义。

从概念上讲，在发送端，消息被发布到发送 (Tx) 上下文。网络处理来自 Tx 上下文的消息，将数据打包成出站消息。尽管许多实现按顺序处理 Tx 上下文（即 Tx 上下文是一个真正的队列），但通过 libfabric API 指定的排序保证决定了实际的处理顺序。一般来说，应用程序对其消息和数据排序越宽松，网络软件和硬件可以利用的优化就越多，从而提供更好的性能。

## 已标记的消息

带标签的消息与消息传输类似，不同之处在于消息携带一条附加信息，即消息标签。标签是应用程序定义的值，是消息传输协议的一部分，用于在接收方路由数据包。从较高层次来看，它们与消息 ID 大致相似。不同之处在于标签值由应用程序设置，可以是任何值，并且允许重复的标签值。

每个发送的消息都带有一个标签值，该标签值用于选择将数据复制到其中的接收缓冲区。在接收端，消息缓冲区也标有标签。从网络到达的消息通过已发布的接收消息进行搜索，直到找到匹配的标签。

标签通常用于标识虚拟通信组或角色。在实践中，消息标签通常分为多个字段。例如，标签的高 16 位可以指示虚拟组，而低 16 位则标识消息目的。libfabric 中的标签消息接口就是围绕这个使用模型设计的。每条发送的消息都携带一个通过 API 指定的标签值。在接收器处，缓冲区与标签值和掩码相关联。掩码用作缓冲区匹配过程的一部分。在根据接收缓冲区检查标签之前，将掩码应用于发送消息中携带的接收标签值。例如，掩码可以指示忽略标签的低 16 位。如果结果值匹配，则认为标签匹配。

出于性能原因，掩码被指定为“忽略”位。尽管这与许多开发人员对掩码的看法相反（其中有效位将设置为 1），但该定义最终与应用程序很好地映射。匹配标签时实际执行的操作是：

```
send_tag | ignore == recv_tag | ignore

/* this is equivalent to:
 * send_tag & ~ignore == recv_tag & ~ignore
 */
```

如果使用单个标签值，则带标签的消息相当于消息传输。但标记消息要求接收方在目标处执行匹配操作，与未标记消息相比，这可能会影响性能。

## 退货授权

RMA 操作的架构使得它们不需要 RMA 目标处的 CPU 进行处理。卸载传输功能的 NIC 可以执行 RMA 操作，而不会影响主机处理。RMA 写操作将数据从发起方传输到目标方。应写入数据的内存位置由传输消息本身携带，并在目标处进行验证检查以防止无效访问。

RMA 读取操作从目标系统获取数据并将其传输回请求的发起者，并在其中将其放入内存中。当 NIC 支持传输卸载时，这也可以在不涉及目标系统上的主机处理器的情况下完成。

RMA 操作的优点是它们解耦了对等点的处理。只要发起者准备好，就可以放置或获取数据，而不必影响对等进程。

由于 RMA 操作允许对等方直接访问进程的内存，因此使用额外的保护机制来防止无意或不需要的访问。通过写入操作更新或通过读取操作获取的 RMA 内存必须注册为具有指定的正确权限的访问权限。

## 原子操作

原子传输用于以原子方式读取和更新位于远程内存区域中的数据。从概念上讲，它们类似于具有相似性质的本地原子操作（例如原子增量、比较和交换等）。原子操作的好处是它们可以将基本算术功能卸载到 NIC 上。与其他仅需要传输数据字节的数据传输操作不同，原子需要了解所访问数据的格式。

单个原子函数对数据数组进行操作，对每个条目应用原子操作。然而，操作的原子性仅限于单个数据类型或条目，但不能跨越整个数组。libfabric 定义了跨所有常见数据类型的各种原子操作。然而，对给定操作的支持取决于提供者的实现。

## 集体经营

一般来说，集体操作可以被认为是一组对等端点之间的协调原子操作，几乎就像多播原子请求。单个集体操作可能会导致从多个对等点收集数据，使用一组原子原语组合数据，并将结果分发给所有对等点。集体行动是集体的沟通交流。它涉及多个对等点与参与集体呼叫的其他对等点交换数据。集体操作需要所有参与成员的密切协调，集体调用可能会给结构以及本地和远程数据缓冲区带来压力。

集体行动是一个深入研究的领域，专门的图书馆几乎完全专注于有效实施集体行动。此类库是 libfabric 的特定目标。libfabric 集合 API 的主要目标是向更高级别的库和应用程序公开用于实现集合的网络加速功能。建议需要集体通信的应用程序以更高级别的库为目标，例如 MPI，而不是为此目的使用 libfabric 集体 API。

------

[© 2023 OpenFabrics 接口工作组在Jekyll Bootstrap](http://jekyllbootstrap.com/) 和[Twitter Bootstrap](http://twitter.github.com/bootstrap/)的帮助下







# fi_setup(7) Libfabric 程序员指南 - 设置

# 姓名

fi_setup - libfabric 设置和初始化

# 概述

libfabric API 的完整描述记录在相关手册页中。本节介绍了选择的接口，包括如何使用它们。它并不试图捕获所有微妙之处或用例，也不描述所有可能的数据结构或字段。然而，它对于尝试开始使用 libfabric 的新开发人员来说非常有用。

# fi_getinfo()

fi_getinfo() 调用是应用程序调用的第一个调用之一。它旨在易于用于简单的应用程序，但可扩展性足以配置网络以获得最佳性能。它有几个目的。首先，它抽象了网络实现和寻址细节。其次，它允许应用程序指定它们需要网络的哪些功能。最后，它为提供商提供了一种机制来报告应用程序如何使用网络以获得最佳性能。fi_getinfo() 大致基于 getaddrinfo() 调用。

```
/* API prototypes */
struct fi_info *fi_allocinfo(void);

int fi_getinfo(int version, const char *node, const char *service,
    uint64_t flags, struct fi_info *hints, struct fi_info **info);
/* Sample initialization code flow */
struct fi_info *hints, *info;

hints = fi_allocinfo();

/* hints will point to a cleared fi_info structure
 * Initialize hints here to request specific network capabilities
 */

fi_getinfo(FI_VERSION(1, 16), NULL, NULL, 0, hints, &info);
fi_freeinfo(hints);

/* Use the returned info structure to allocate fabric resources */
```

hins 参数是请求 Fabric 服务的关键。fi_info 结构包含多个数据字段，以及指向各种属性的指针。fi_allocinfo() 调用简化了 fi_info 结构的创建，强烈建议使用。在此示例中，应用程序只是尝试获取系统中可用的提供程序及其支持的功能的列表。请注意，API 被设计为可扩展的。版本控制信息作为 fi_getinfo() 调用的一部分提供。libfabric 使用该版本来确定应用程序了解哪些 API 功能。在这种情况下，应用程序表明它可以正确处理为 1.16 版本（或更早版本）定义的任何功能。

应用程序应*始终*将其编写的版本硬编码到 fi_getinfo() 调用中。这确保了较新版本的 libfabric 将提供与应用程序使用的版本的向后兼容性。新版本的 libfabric 必须支持针对旧版本库编译的应用程序。它还必须支持针对旧库版本中的头文件编写的应用程序，但针对较新的头文件重新编译。除此之外，版本参数允许 libfabric 确定应用程序是否知道可能已添加到结构中的新字段，或者这些字段中的数据是否可能未初始化。

通常，应用程序将初始化提示参数以列出它将使用的功能。

```
/* Taking a peek at the contents of fi_info */
struct fi_info {
    struct fi_info *next;
    uint64_t caps;
    uint64_t mode;
    uint32_t addr_format;
    size_t src_addrlen;
    size_t dest_addrlen;
    void *src_addr;
    void *dest_addr;
    fid_t handle;
    struct fi_tx_attr *tx_attr;
    struct fi_rx_attr *rx_attr;
    struct fi_ep_attr *ep_attr;
    struct fi_domain_attr *domain_attr;
    struct fi_fabric_attr *fabric_attr;
    struct fid_nic *nic;
};
```

fi_info 结构引用几个不同的属性，这些属性对应于应用程序分配的不同 libfabric 对象。对于基本应用程序来说，修改或访问大多数属性字段是不必要的。许多应用程序只需要处理 fi_info 的几个字段，最值得注意的是端点类型、功能（上限）位和模式位。这些在下面有更详细的定义。

成功时， fi_getinfo() 函数返回 fi_info 结构的链接列表。列表中的每个条目都将满足通过hins 参数指定的条件。返回的条目可能来自不同的网络提供商，或者返回的属性可能不同。例如，如果提示未指定特定端点类型，则三种端点类型中的每一种都可能有一个条目。作为一般规则，libfabric 尝试按从最理想到最不理想的顺序返回 fi_info 结构列表。高性能网络提供商列在更通用的提供商之前。

## 功能 (fi_info::caps)

fi_info caps 字段用于指定应用程序所需的网络功能和服务。该字段是所需功能的位掩码。前面提到的每个数据传输服务都有能力位：FI_MSG、FI_TAGGED、FI_RMA、FI_ATOMIC 和 FI_COLLECTIVE。应用程序应为其将使用的每组操作设置每一位。这些位通常是应用程序设置的唯一上限位。

能力分为三大类：主要、次要和主要修饰符。应用程序必须明确请求主要功能，并且提供者必须仅启用对所选主要功能的支持。出于性能和安全原因，这是必需的。主要修饰符用于限制主要功能，例如将端点限制为仅发送。

应用程序可以选择请求辅助功能。如果有请求，如果 fi_getinfo 请求被请求或失败，则提供者必须支持某项功能。如果这样做不会损害性能或安全性，则提供商可以选择报告非请求的辅助功能。即，提供者可以授予应用程序第二能力，无论该应用程序。最常访问的辅助功能位指示提供程序通信是否仅限于本地节点（例如，共享内存提供程序仅支持本地通信）和/或远程节点（对于缺乏环回支持的 NIC 可能是这种情况）。其他辅助功能位主要处理针对高度可扩展应用程序的功能，但可能无法跨多个提供商普遍支持。

由于不同的提供商支持不同的功能集，因此需要最佳网络性能的应用程序可能需要针对存在或不存在的功能进行编码。如果存在，此类功能可以提供可扩展性或性能提升。当不存在时，应用程序可能更愿意调整其协议或实现以解决网络限制。尽管提供商通常可以模拟功能，但这样做可能会影响整体性能，包括数据传输的性能，否则这些性能似乎与所使用的功能无关。例如，如果提供者需要将协议标头插入消息流中以实现给定的功能，则该标头的插入可能会对所有传输的性能产生负面影响。通过向应用程序公开此类限制，

建议应用程序仅针对实现最佳性能所需的功能进行编码。如果某个功能对整体性能几乎没有影响，那么开发人员应避免在初始实现中使用此类功能。这将使应用程序能够在最广泛的硬件上正常工作。然后，应用程序优化可以添加对不太常见功能的支持。要查看哪些提供程序支持哪些功能，请参阅 相关版本的libfabric[提供程序功能 Maxtrix 。](https://github.com/ofiwg/libfabric/wiki/Provider-Feature-Matrix)

## 模式位 (fi_info::mode)

其中功能位代表应用程序所需的功能，模式位对应于提供者所需的行为。也就是说，能力位是自上而下的请求，而模式位是自下而上的限制。模式位由提供商设置，以请求应用程序以特定方式使用 API，以实现最佳性能。模式位通常意味着，如果由应用程序实现，那么实现应用程序所需的某些通信语义的额外工作将比强制将相同的实现交给提供程序要少。模式位是由于硬件实现限制而产生的。

应用程序开发人员在开发过程中决定他们想要或可以轻松支持哪些模式位。每个模式位描述应用程序必须遵循的特定行为才能使用各种接口。应用程序在调用 fi_getinfo() 时设置它们支持的模式位。如果提供程序需要未设置的模式位，则 fi_getinfo() 将跳过该提供程序。如果提供程序不需要设置模式位，它将响应 fi_getinfo() 调用，并清除模式位。这表明应用程序不需要执行模式位所需的操作。

提供者所需的共模位之一是 FI_CONTEXT（和 FI_CONTEXT2）。此模式位要求应用程序将 libfabric 定义的数据结构 (struct fi_context) 传递到任何数据传输函数中。在数据传输操作完成之前，该结构必须保持有效且不被应用程序使用。该模式位背后的目的是结构 fi_context 提供提供者可用于跟踪请求的“临时”空间。例如，它可能需要在请求待处理时将其插入到链接列表中，或者跟踪出站传输已重试的次数。由于许多应用程序已经使用自己的数据结构跟踪未完成的操作，因此通过将 struct fi_context 嵌入到同一结构中，可以提高整体性能。

继续这个示例，如果应用程序尚未跟踪未完成的请求，则它将不设置 FI_CONTEXT 模式位。这表明提供者需要获取并发布其自己的结构以用于跟踪目的。在这种情况下，无论是由应用程序还是提供商完成，成本基本上是相同的。

为了最广泛地支持不同的网络技术，应用程序应尝试支持尽可能多的模式位。建议提供商支持不支持任何模式位的应用程序，并尽可能减少影响。然而，即使模式位被禁用，在提供程序中实现模式位避免仍然会影响性能。因此，一些提供商可能总是要求设置特定的模式位。

# FID (fid_t)

FID 代表织物标识符。它是分配给所有 libfabric API 对象的基本对象类型。所有结构资源均由 fid 结构表示，并且所有 fid 均源自基本 fid 类型。用面向对象的术语来说，fid 就是父类。fid 的内容对应用程序是可见的。

```
/* Base FID definition */
enum {
    FI_CLASS_UNSPEC,
    FI_CLASS_FABRIC,
    FI_CLASS_DOMAIN,
    ...
};

struct fi_ops {
    size_t size;
    int (*close)(struct fid *fid);
    ...
};

/* All fabric interface descriptors must start with this structure */
struct fid {
    size_t fclass;
    void *context;
    struct fi_ops *ops;
};
```

fid 结构被设计为最小化内存占用与软件开销之间的权衡。每个 fid 都被标识为一个特定的对象类，这有助于调试。上面给出了示例（例如 FI_CLASS_FABRIC）。上下文字段是应用程序定义的数据值，在对象创建期间分配给该对象。上下文字段的使用是特定于应用程序的，但它旨在由应用程序读取。应用程序通常将上下文设置为其分配的相应结构。上下文字段是建议应用程序直接访问的唯一字段。对其他字段的访问应使用定义的函数调用（例如 close() 操作）来完成。

ops 字段指向一组函数指针。fi_ops 结构定义适用于该类的操作。fi_ops 结构中的大小字段用于可扩展性，并允许 fi_ops 结构在添加新操作时以向后兼容的方式增长。fid故意指向fi_ops结构，而不是直接嵌入操作。这允许多个 fid 指向同一组操作，从而最大限度地减少每个 fid 的内存占用。（在内部，提供者通常将 ops 设置为静态数据结构，并动态分配 fid 结构。）

尽管应用程序可以直接访问函数指针，但强烈建议使用手册页中定义的静态内联函数。这是使用 FABRIC_DIRECT 库功能构建的应用程序所必需的。（FABRIC_DIRECT 是一个编译时选项，它允许通过将应用程序与特定提供程序紧密耦合来实现高度优化的构建。）

其他 OFI 类均从此结构派生，添加了自己的操作集。

```
/* Example of deriving a new class for a fabric object */
struct fi_ops_fabric {
    size_t size;
    int (*domain)(struct fid_fabric *fabric, struct fi_info *info,
        struct fid_domain **dom, void *context);
    ...
};

struct fid_fabric {
    struct fid fid;
    struct fi_ops_fabric *ops;
};
```

其他 fid 类遵循与 fid_fabric 所示类似的模式。基本 fid 结构后面跟着零个或多个指向操作集的指针。

# 面料（fid_fabric）

应用程序打开的顶级对象是结构标识符。该结构通常可以被应用程序视为容器对象，尽管它确实标识了应用程序使用哪些提供者。

在调用 fi_getinfo() 之后，打开结构通常是一个简单的调用。

```
int fi_fabric(struct fi_fabric_attr *attr, struct fid_fabric **fabric, void *context);
```

结构属性可以直接从 struct fi_info 访问。新打开的fabric通过'fabric'参数返回。“context”参数出现在许多操作中。它是与结构关联的用户指定值。它可用于指向应用程序特定的结构，并且可从 struct fid_fabric 中检索。

## 属性（fi_fabric_attr）

织物属性很简单。

```
struct fi_fabric_attr {
    struct fid_fabric *fabric;
    char *name;
    char *prov_name;
    uint32_t prov_version;
    uint32_t api_version;
};
```

应用程序可能直接使用的唯一字段是 prov_name。这是一个字符串值，提示可以使用它来选择要使用的特定提供程序。在大多数系统上，将有多个可用的提供程序。只有一个可能代表连接到系统的高性能网络。其他提供程序是可在任何系统上使用的通用提供程序，例如 TCP 套接字和 UDP 提供程序。

Fabric字段用于帮助应用程序管理开放的Fabric资源。如果应用程序已经打开了可以支持返回的 fi_info 结构的结构，则这将设置为该结构。

# 域（fid_domain）

域经常映射到特定的本地网络接口适配器。域可以指整个 NIC、多端口 NIC 上的端口、NIC 公开的虚拟设备、以多轨方式使用的多个 NIC 等等。尽管将域视为引用 NIC 很方便，但 libfabric 并不期望这种关联。从应用程序的角度来看，域标识了一组可以一起使用的资源。

与结构类似，调用 fi_getinfo() 后打开域非常简单。

```
int fi_domain(struct fid_fabric *fabric, struct fi_info *info,
    struct fid_domain **domain, void *context);
```

从 fi_getinfo() 返回的 fi_info 结构可以直接传递给 fi_domain() 以打开新域。

## 属性（fi_domain_attr）

域的目标之一是定义数据传输服务（端点）和完成服务（完成队列和计数器）之间的关系。许多域属性描述了这种关系及其对应用程序的影响。

```
struct fi_domain_attr {
    struct fid_domain *domain;
    char *name;
    enum fi_threading threading;
    enum fi_progress control_progress;
    enum fi_progress data_progress;
    enum fi_resource_mgmt resource_mgmt;
    enum fi_av_type av_type;
    enum fi_mr_mode mr_mode;
    size_t mr_key_size;
    size_t cq_data_size;
    size_t cq_cnt;
    size_t ep_cnt;
    size_t tx_ctx_cnt;
    size_t rx_ctx_cnt;
    ...
```

域属性及其含义的完整详细信息位于 fi_domain 手册页中。下面描述了有关选定属性及其对应用程序的影响的信息。

## 线程（fi_threading）

libfabric 定义了独特的线程模型。libfabric 设计深受面向对象编程概念的影响。多线程应用程序必须确定如何在其线程之间分配 libfabric 对象（域、端点、完成队列等），或者是否有任何线程可以访问任何对象。例如，应用程序可以生成一个新线程来处理每个新连接的端点。域线程字段为应用程序提供了一种机制来识别哪些对象可以由不同线程同时访问。这反过来又允许提供者优化，或者在某些情况下，消除围绕这些对象的内部同步和锁定。

线程定义了提供者可以优化同步原语的位置。然而，提供者仍然可能实现比应用程序需要的更多的序列化。（这通常是使提供程序实现更简单的结果）。

建议应用程序以 FI_THREAD_SAFE（由提供程序实现的完整线程安全）或 FI_THREAD_DOMAIN（与单个域关联的对象只能由单个线程访问）为目标。

## 进度（fi_progress）

进度模型是使用主机处理器执行传输协议的某些部分的结果。为了简化开发，libfabric定义了两种进度模型：自动或手动。它不会尝试识别哪些特定的接口功能可以被卸载，或者哪些操作需要应用程序线程的额外处理。

自动进度意味着应用程序启动的操作最终将完成，即使应用程序不再调用 libfabric API。该操作要么完全卸载到硬件上，提供程序使用内部线程，要么操作系统内核可以执行该任务。在后两种情况下，使用自动进度可能会增加系统开销和延迟。对于控制操作，例如连接设置，这通常是可以接受的。但是，对数据传输的影响可能是可衡量的，特别是在需要内部线程提供自动进度的情况下。

对于不将所有传输功能卸载到硬件中的提供商来说，手动进度模型可以避免这种开销。通过手动操作，提供程序实现将处理传输操作作为特定 libfabric 函数的一部分。例如，对 fi_cq_read() 的调用（检索已完成操作的数组）也可能负责发送 ack 消息以通知对等方已收到消息。由于读取完成队列是应用程序正常操作的一部分，因此对应用程序的影响最小，并且避免了额外的线程。

应用程序在使用手动进度时需要小心，特别是当它们通过不同的代码路径或库依赖项多次链接到 libfabric 时。如果应用程序线程用于驱动进度，例如使用 ACK 响应接收到的数据，那么应用程序线程及时调用 libfabric 至关重要。

## 内存注册（fid_mr）

RMA、原子和集体操作可以读取和写入对等进程拥有的内存，并且不需要目标处理器的参与。由于可以通过网络修改内存，因此应用程序必须选择将其内存公开给对等方。这是由内存注册过程处理的。注册的内存区域将内存缓冲区与授予结构资源访问权限相关联。内存缓冲区必须先注册，然后才能用作远程 RMA、原子或集体数据传输的目标。此外，即使在本地传输的情况下，结构提供商也可能要求在使用数据缓冲区之前注册数据缓冲区。后者对于确保网络硬件执行传输时虚拟到物理页面映射不会更改是必要的。

为了处理不同的硬件要求，有一组与内存注册相关的 mr_mode 位。mr_mode 位的行为与 fi_info 模式位类似。应用程序指示它们可以支持哪些类型的限制，并且提供者清除那些不需要的位。

对于需要内存注册的硬件，管理注册对于实现良好的性能和可扩展性至关重要。注册内存的行为成本高昂，应该在每次数据传输的基础上避免。libfabric 对管理内存注册、对用户应用程序隐藏注册、缓存注册以减少每次传输开销以及检测缓存注册何时不再有效具有广泛的内部支持。建议本机设计不考虑注册内存的应用程序使用 libfabric 的注册缓存。这可以通过简单地不设置相关的 mr_mode 位来完成。

### 内存区域 API

以下 API 重点介绍如何分配和访问已注册的内存区域。请注意，这不是内存区域 (MR) 调用的完整列表，有关每个 API 的完整详细信息，读者应直接参阅 fi_mr 手册页。

```
int fi_mr_reg(struct fid_domain *domain, const void *buf, size_t len,
    uint64_t access, uint64_t offset, uint64_t requested_key, uint64_t flags,
    struct fid_mr **mr, void *context);

void * fi_mr_desc(struct fid_mr *mr);
uint64_t fi_mr_key(struct fid_mr *mr);
```

默认情况下，内存区域与域关联。MR 可由在该域上打开的任何端点访问。区域从“buf”指定的地址开始，长度为“len”字节。“access”参数是通过 OR 组合在一起的权限标志。权限指示可以针对该区域调用哪种类型的操作（例如FI_READ、FI_WRITE、FI_REMOTE_READ、FI_REMOTE_WRITE）。“buf”参数通常引用分配的虚拟内存。

MR与本地和远程保护锁相关联。本地密钥称为内存描述符，可以通过调用 fi_mr_desc() 来检索。仅当 FI_MR_LOCAL mr_mode 位已设置时才需要此调用。内存描述符直接传递到数据传输操作中，例如：

```
/* fi_mr_desc() example using fi_send() */
fi_send(ep, buf, len, fi_mr_desc(mr), 0, NULL);
```

当使用 RMA 或原子操作瞄准 MR 时，对等方使用远程密钥（或简称 MR 密钥）。在许多情况下，密钥需要在单独的消息中发送给发起方。libfabric API 使用 64 位密钥（其中使用的是 64 位密钥）。提供商使用的实际密钥大小是其域属性的一部分 支持较大密钥大小（某些提供商要求）通过 mr_mode 位来传达，并且需要使用扩展 MR API 调用将较大大小映射到 64 - 位值。

# 端点

端点是传输级通信门户。调用 fi_getinfo() 后，打开端点非常简单。

## 活跃 (fid_ep)

活动端点可以是面向连接的或无连接的。它们被认为是活动的，因为它们可用于执行数据传输。所有数据传输接口 – 消息 (fi_msg)、标记消息 (fi_tagged)、RMA (fi_rma)、原子 (fi_atomic) 和集合 (fi_collective) – 都与活动端点关联。尽管单个端点可能无法使用所有数据传输。在标准配置中，活动端点具有一个发送队列和一个接收队列。一般来说，在结构上生成流量的操作都会被发布到传输队列中。这包括所有 RMA 和原子操作，以及发送的消息和发送的标记消息。为接收传入数据而发布缓冲区的操作被提交到接收队列。

活动端点在禁用状态下创建。在启用端点之前，必须首先对其进行配置。在接受数据传输操作（包括接收缓冲区的发布）之前，端点必须转换为启用状态。fi_enable() 调用用于将活动端点转换为启用状态。fi_connect() 和 fi_accept() 调用还将端点转换为启用状态（如果尚未启用）。

```
int fi_endpoint(struct fid_domain *domain, struct fi_info *info,
    struct fid_ep **ep, void *context);
```

### 启用（fi_enable）

为了将端点转换为启用状态，它必须绑定到一个或多个结构资源。这包括将端点绑定到完成队列和事件队列。未连接的端点也必须绑定到地址向量。

```
/* Example to enable an unconnected endpoint */

/* Allocate an address vector and associated it with the endpoint */
fi_av_open(domain, &av_attr, &av, NULL);
fi_ep_bind(ep, &av->fid, 0);

/* Allocate and associate completion queues with the endpoint */
fi_cq_open(domain, &cq_attr, &cq, NULL);
fi_ep_bind(ep, &cq->fid, FI_TRANSMIT | FI_RECV);

fi_enable(ep);
```

在上面的例子中，我们分配了一个AV和CQ。AV 和 CQ 的属性被省略（下面的附加讨论）。然后通过 fi_ep_bind() 调用将它们与端点关联。将所有必要的资源分配给端点后，我们启用它。启用端点向提供者表明它应该分配任何硬件和软件资源并完成端点的初始化。（如果端点未绑定到所有必需的资源，则 fi_enable() 调用将失败。）

fi_enable() 调用始终针对未连接的端点进行调用。连接的端点可能能够跳过调用 fi_enable()，因为 fi_connect() 和 fi_accept() 将自动启用端点。然而，应用程序仍然可以在调用 fi_connect() 或 fi_accept() 之前调用 fi_enable()。这样做允许应用程序将接收缓冲区发布到端点，这确保了在对等端点在建立连接后立即发送消息的情况下它们可用于接收数据。

## 被动（fid_pep）

被动端点用于侦听传入的连接请求。被动端点的类型为 FI_EP_MSG，并且可能不执行任何数据传输。希望创建被动端点的应用程序通常使用 FI_SOURCE 标志调用 fi_getinfo()，通常仅指定“服务”地址。服务地址对应于TCP端口号。

被动端点与事件队列关联。事件队列报告来自对等方的连接请求。与主动端点不同，被动端点不与域关联。这允许应用程序跨多个域侦听连接请求，但仍仅限于单个提供商。

```
/* Example passive endpoint listen */
fi_passive_ep(fabric, info, &pep, NULL);

fi_eq_open(fabric, &eq_attr, &eq, NULL);
fi_pep_bind(pep, &eq->fid, 0);

fi_listen(pep);
```

在调用监听之前，被动端点必须绑定到事件队列。这确保了可以将连接请求报告给应用程序。要接受新连接，应用程序等待请求，为其分配新的活动端点，然后接受请求。

```
/* Example accepting a new connection */

/* Wait for a CONNREQ event */
fi_eq_sread(eq, &event, &cm_entry, sizeof cm_entry, -1, 0);
assert(event == FI_CONNREQ);

/* Allocate a new endpoint for the connection */
if (!cm_entry.info->domain_attr->domain)
    fi_domain(fabric, cm_entry.info, &domain, NULL);
fi_endpoint(domain, cm_entry.info, &ep, NULL);

fi_ep_bind(ep, &eq->fid, 0);
fi_cq_open(domain, &cq_attr, &cq, NULL);
fi_ep_bind(ep, &cq->fid, FI_TRANSMIT | FI_RECV);

fi_enable(ep);
fi_recv(ep, rx_buf, len, NULL, 0, NULL);

fi_accept(ep, NULL, 0);
fi_eq_sread(eq, &event, &cm_entry, sizeof cm_entry, -1, 0);
assert(event == FI_CONNECTED);
```

连接请求事件 (FI_CONNREQ) 包括有关要分配的端点类型的信息，包括要使用的默认属性。如果尚未为端点打开域，则必须打开一个域。然后可以分配端点和相关资源。与上面未连接的端点示例不同，已连接的端点没有 AV，但需要绑定到事件队列。在本例中，我们使用相同的 EQ 作为监听端点。一旦其他EP资源（例如CQ）被分配和绑定，EP就可以被启用。

要接受连接，应用程序调用 fi_accept()。请注意，由于线程同步问题，活动端点甚至可以在 fi_accept() 返回之前接收数据。在调用 fi_accept() 之前发送接收缓冲区可以处理这种情况，从而避免连接后立即发生网络流量控制问题。

fi_eq_sread() 调用是对事件队列的阻塞（同步）读取调用。这些调用等待事件发生，在本例中是连接请求和建立事件。

## EP 属性 (fi_ep_attr)

端点的属性是使用端点属性指定的。这些是端点的整体属性。还有一些与支持端点的传输和接收上下文特别相关的附加属性（详细信息如下）。

```
struct fi_ep_attr {
    enum fi_ep_type type;
    uint32_t        protocol;
    uint32_t        protocol_version;
    size_t          max_msg_size;
    ...
};
```

fi_endpoint 手册页中提供了每个字段的完整描述，下面列出了选定的详细信息。

### 端点类型 (fi_ep_type)

这指示端点的类型：可靠数据报（FI_EP_RDM）、可靠连接（FI_EP_MSG）或不可靠数据报（FI_EP_DGRAM）。几乎所有应用程序都希望将端点类型指定为传递到 fi_getinfo 的提示，因为大多数应用程序仅被编码为支持单个端点类型。

### 最大消息大小 (max_msg_size)

此大小是通过端点的任何数据传输操作的最大大小。对于不可靠的数据报端点，这通常是底层网络的 MTU。对于可靠的端点，该值通常是底层传输协议的限制。常见的最小最大消息大小为 2GB，但某些提供商支持任意大的大小。需要大于最大报告大小的传输的应用程序需要将单个大型传输分解为多个操作。

提供商将其硬件或网络限制暴露给应用程序，而不是在内部分段大型传输，以最大限度地减少完成开销。例如，对于内部支持大型消息分段的提供程序，即使从未使用过大于传输支持的最大值的传输，也需要在软件中模拟所有完成机制（队列和计数器）。

### 消息订单大小 (max_order_xxx_size)

这些字段指定数据顺序。它们定义了 RMA 和原子操作将传输数据传输到目标内存的顺序。数据排序需要消息排序。如果未指定消息顺序，则这些字段不适用。

例如，假设应用程序向同一目标内存位置发出两个 RMA 写入操作。（例如，应用程序可能会在每次满足本地条件时写入时间戳值）。消息排序指示发送方发起的第一个写入是接收方处理的第一个写入。*数据排序指示来自第一次写入的数据*是否在第二次写入更新内存之前更新内存。

max_order_xxx_size 字段指示在仍实现数据排序的情况下消息可以有多大。如果字段为 0，则无法保证数据顺序。如果某个字段与 max_msg_size 相同，则保证所有消息的数据顺序。

对于相同的背靠背操作，提供程序可能支持最大 max_msg_size 的数据排序。例如，RMA 写入之后的 RMA 写入可能具有数据排序，而不管数据传输的大小 (max_order_waw_size = max_msg_size)。混合操作（例如先读后写）通常受到限制。*这是因为 RMA 读取操作可能需要来自发起者*的确认，这会影响重传协议。

例如，考虑 RMA 读取，然后写入。目标将处理读取请求、检索数据并发送回复。发生这种情况时，会收到一个写入，该写入想要更新读取所访问的同一内存位置。如果目标处理写入，它将覆盖读取所使用的内存。如果读取响应丢失，并且重试读取，目标将无法重新发送数据。为了处理这个问题，目标要么需要：推迟处理写入，直到收到读取响应的确认，缓冲读取响应以便可以重新传输，或者指示不保证数据排序。

由于读取或写入操作的大小可能是千兆字节，因此推迟写入可能会显着增加延迟，并且缓冲读取响应可能不切实际。max_order_xxx_size 字段指示在仍保持排序的情况下背靠背操作可以有多大。在许多情况下，先写后读以及写读顺序可能受到很大限制，但仍然可用于实现特定算法，例如全局锁定机制。

## Rx/Tx 上下文属性 (fi_rx_attr / fi_tx_attr)

端点属性定义了端点的整体能力；然而，专门应用于接收或发送上下文的属性分别由 struct fi_rx_attr 和 fi_tx_attr 定义：

```
struct fi_rx_attr {
    uint64_t caps;
    uint64_t mode;
    uint64_t op_flags;
    uint64_t msg_order;
    uint64_t comp_order;
    ...
};

struct fi_tx_attr {
    uint64_t caps;
    uint64_t mode;
    uint64_t op_flags;
    uint64_t msg_order;
    uint64_t comp_order;
    size_t inject_size;
    ...
};
```

Rx/Tx 上下文功能必须是端点功能的子集。对于许多应用程序来说，提供者返回的默认属性就足够了，应用程序只需要指定端点属性。

两个上下文属性都包含 op_flags 字段。应用程序使用此字段来指定用于任何调用的默认操作标志。例如，通过将传输上下文的 op_flags 设置为 FI_INJECT，应用程序已向提供者指示所有传输操作都应假定需要“注入”行为。即，提供给调用的缓冲区必须在从函数返回时返回到应用程序。op_flags 适用于在调用过程中不提供标志的所有操作（例如 fi_sendmsg）。op_flags 的一种用途是指定应用程序所需的默认完成语义（接下来讨论）。通过在初始化时设置默认的 op_flags，我们可以避免将标志作为参数传递到某些数据传输调用中，避免解析标志，

应当注意，一些属性依赖于具有支持属性的对等端点，以便实现正确的应用程序行为。例如，消息顺序必须在发起方的发送属性和目标的接收属性之间兼容。任何不匹配都可能导致难以调试的错误行为。

# 竣工数量

数据传输操作异步完成。Libfabric 定义了两种可以通知应用程序操作已完成的机制：完成队列和计数器。无论使用哪种机制来通知应用程序操作已完成，开发人员都必须了解完成指示的含义。

在所有情况下，完成都表明可以安全地重用与数据传输关联的缓冲区。此完成模式称为 *注入*完成，对应于操作标志 FI_INJECT_COMPLETE。然而，完成也可以保证更强的语义。

尽管 libfabric 没有定义实现，但提供程序可以通过在生成完成之前将应用程序的缓冲区复制到网络缓冲区来满足注入完成的要求。即使传输操作丢失并且必须重试，提供商也可以从复制的位置重新发送原始数据。对于大型传输，提供者可能不会将请求标记为注入完成，直到目标确认数据为止。然而，应用程序应该只推断重复使用其数据缓冲区来完成注入操作是安全的。

Transmit Complete是一种为应用程序提供稍强保证的完成模式。传输完成的含义取决于端点是否可靠。对于不可靠端点 (FI_EP_DGRAM)，传输完成表示请求已传送到网络。也就是说，消息至少已传递到本地 NIC 上的硬件队列。对于可靠端点，当请求到达目标端点时，传输完成。通常，这表明目标已确认请求。传输完整映射到操作标志 FI_TRANSMIT_COMPLETE。

第三种完成模式被定义为提供超出传输完成的保证。传输完成后，应用程序知道该消息不再依赖于本地 NIC 或网络（例如交换机）。然而，数据可能在远程NIC处缓冲并且不一定被写入目标存储器。因此，请求中发送的数据可能并非对所有进程都可见。第三种完成方式是交付完成。

交付完成表示操作结果可供结构上的所有进程使用。传输和交付完成之间的区别很微妙，但很重要。它通常处理目标端点*何时*生成消息确认。对于将传输协议卸载到 NIC 的提供商来说，对传输完成的支持很常见。在主机处理器上实现部分协议的提供商更容易满足交付完整的保证。交付完成对应于 FI_DELIVERY_COMPLETE 操作标志。

通过将上述完成标志之一设置为上下文属性的 op_flags，应用程序可以在打开端点时请求默认完成模式。但是，通常建议应用程序使用提供程序的默认标志以获得最佳性能，并修改其协议以实现其完成语义。例如，许多应用程序将执行“最终确定”或“提交”过程作为其操作的一部分，这会同步所有对等方的处理并保证已接收到所有先前发送的数据。

fi_cq 手册页中给出了完成语义的完整讨论。

## CQ (fid_cq)

完成队列通常直接映射到提供者硬件机制，而 libfabric 的设计是为了最大限度地减少访问这些机制对软件的影响。与目前讨论的其他对象（结构、域、端点）不同，完成队列不是 fi_info 结构的一部分，也不参与 fi_getinfo() 调用。

所有活动端点必须与一个或多个完成队列绑定。即使应用程序会抑制完成（例如使用 FI_SELECTIVE_COMPLETION 标志），情况也是如此。需要完成队列来报告错误完成的操作，并在手动进度的情况下帮助推动进度。

CQ 与端点分开分配，并通过 fi_ep_bind() 函数与端点关联。

## CQ 格式 (fi_cq_format)

为了最小化提供者必须报告的数据量，写回应用程序的完成数据的类型是可选择的。这限制了提供程序写入内存的字节数，并允许必要的完成数据适合紧凑的结构。每个 CQ 格式映射到一个特定的完成结构。开发人员应该分析每个结构，选择包含其所需的所有数据的最小结构，并将相应的枚举值指定为 CQ 格式。

例如，如果应用程序只需要知道哪个请求已完成以及收到的消息的大小，则可以选择以下内容：

```
cq_attr->format = FI_CQ_FORMAT_MSG;

struct fi_cq_msg_entry {
    void      *op_context;
    uint64_t  flags;
    size_t    len;
};
```

一旦选择了格式，底层提供程序将假设针对 CQ 的读取操作将传入相应结构的数组。CQ 数据格式的设计使得报告更多信息的结构可以转换为报告更少信息的结构。

## 读取完成 (fi_cq_read)

可以使用非阻塞调用 fi_cq_read / fi_cq_readfrom 之一或阻塞调用 fi_cq_sread / fi_cq_sreadfrom 之一从 CQ 读取完成。无论使用哪个调用，应用程序都会根据所选的 CQ 格式传入一系列完成结构。CQ 接口针对批量完成处理进行了优化，允许应用程序从单个读取调用中检索多个完成。read 和 readfrom 调用之间的区别在于 readfrom 返回源寻址数据（如果可用）。调用的读取派生仅对未连接的端点有用，并且仅当相应端点已配置了 FI_SOURCE 功能时。

FI_SOURCE 要求提供者使用原始完成数据中可用的源地址（例如数据包的源地址）来检索端点地址向量中的匹配条目。在其数据包中携带某种源标识符的应用程序可以避免与使用 FI_SOURCE 相关的开销。

### 检索错误

由于所选的完成结构不足以报告调试或处理错误完成的操作所需的所有数据，因此使用单独的 fi_cq_readerr() 函数报告失败的操作。此调用将 CQ 错误条目结构作为输入，该结构允许提供程序报告有关失败原因的更多信息。

```
/* read error prototype */
fi_cq_readerr(struct fid_cq *cq, struct fi_cq_err_entry *buf, uint64_t flags);

/* error data structure */
struct fi_cq_err_entry {
    void      *op_context;
    uint64_t  flags;
    size_t    len;
    void      *buf;
    uint64_t  data;
    uint64_t  tag;
    size_t    olen;
    int       err;
    int       prov_errno;
    void      *err_data;
    size_t    err_data_size;
};

/* Sample error handling */
struct fi_cq_msg_entry entry;
struct fi_cq_err_entry err_entry;
int ret;

ret = fi_cq_read(cq, &entry, 1);
if (ret == -FI_EAVAIL)
    ret = fi_cq_readerr(cq, &err_entry, 0);
```

如图所示，如果错误条目已插入完成队列，则尝试读取 CQ 将导致读取调用返回 -FI_EAVAIL（错误可用）。这表明应用程序必须使用 fi_cq_readerr() 调用来删除失败操作的完成信息，然后才能从 CQ 中获取其他完成信息。

有关故障的结构错误代码将报告为 fi_cq_err_entry 结构中的 err 字段。还可以通过 prov_errno 字段获取提供商特定的错误代码。可以使用 fi_cq_strerror() 例程将该字段解码为可显示的字符串。err_data 字段是提供商特定的数据，可帮助提供商解码失败的原因。

# 地址向量 (fid_av)

地址向量的主要目标是允许应用程序与数千到数百万对等点进行通信，同时最大限度地减少存储对等点寻址信息所需的数据量。它将结构特定的寻址细节从应用程序推送到提供商。这使得提供商能够优化将地址转换为路由数据的方式，并实现应用程序在不了解低级结构寻址细节的情况下可能难以实现的数据压缩技术。例如，提供商可能能够通过算法计算寻址组件，而不是在本地存储数据。此外，提供商可以与资源管理实体或结构管理器代理进行通信，以获得服务质量或有关结构的其他信息，以便提高网络利用率。

同样重要的目标是确保生成的接口（尤其是数据传输操作）快速且易于使用。从概念上讲，地址向量将端点地址转换为 fi_addr_t。fi_addr_t（结构接口地址数据类型）是一个 64 位值，用于所有“快速路径”操作 - 数据传输和完成。

地址向量与域对象相关联。这允许提供商在硬件中实现地址向量的部分，例如服务质量映射。

## AV 类型 (fi_av_type)

地址向量有两种类型。该类型是指插入到 AV 中的地址的返回 fi_addr_t 值的格式。对于 FI_AV_TABLE 类型，返回的地址是简单的索引，开发人员可能会将 AV 视为地址数组。插入 AV 中的每个地址都映射到下一个空闲数组槽的索引。FI_AV_TABLE 的优点是应用程序可以使用简单索引引用对等点，从而消除应用程序存储任何寻址数据的需要。即应用程序可以自己生成 fi_addr_t 值。这种类型很好地映射到应用程序，例如 MPI，其中对等点按等级引用。

第二种类型是FI_AV_MAP。此类型没有为 fi_addr_t 值定义任何特定格式。使用类型映射的应用程序在发出数据传输操作时需要为给定对等点提供正确的 fi_addr_t。FI_AV_MAP 的优点是提供者可以使用 fi_addr_t 对目标地址进行编码，从而避免从内存中检索数据。作为一个简单的示例，请考虑使用基于 TCP/IPv4 的寻址的结构。fi_addr_t 足够大以包含地址，这允许提供者将数据从 fi_addr_t 直接复制到传出数据包中。

## 在进程之间共享 AV

大规模并行程序通常在每个节点上分配多个进程来运行。由于这些进程与同一组对等点通信，因此每个进程所需的寻址数据是相同的。Libfabric 定义了一种机制，在同一节点上运行的进程可以共享其地址向量。这允许系统维护寻址数据的单个副本，而不是每个进程一个副本。

尽管 libfabric 不需要任何如何共享地址向量的实现，但接口可以很好地映射到使用共享内存。将共享的地址向量被赋予应用程序特定的名称。应用程序如何选择避免与不相关进程发生冲突的名称，或者如何与对等进程通信名称超出了 libfabric 的范围。

共享AV除了有名字之外，还有一个基本映射地址——map_addr。map_addr 的使用仅对于 FI_AV_MAP 类型的地址向量很重要，并且允许应用程序共享 fi_addr_t 值。从应用程序的角度来看，map_addr 是所有 fi_addr_t 值的基值。map_addr 的常见用途是创建初始地址向量的过程，以向提供者请求值，与其对等方交换返回的 map_addr，以及让对等方使用相同的 map_addr 打开共享 AV。这允许 fi_addr_t 值存储在所有对等点都可以访问的共享内存中。

# 使用本机等待对象：TryWait

使用 libfabric 完成对象与套接字之间有一个重要的区别，从目前的讨论来看，这一区别可能并不明显。对于套接字，发出信号的对象与抽象队列的对象相同，即文件描述符。当在套接字上接收到数据时，该数据被放置在与 fd 直接关联的队列中。从 fd 读取会检索该数据。如果应用程序希望阻塞直到数据到达套接字，它会在 fd 上调用 select() 或 poll()。当收到消息时，fd 会发出信号，这会释放阻塞的线程，允许其读取 fd。

通过将等待对象与底层数据队列相关联，应用程序可以使用易于使用且无竞争的接口。如果在调用 select() 或 poll() 时可以从套接字读取数据，则这些调用只会返回 fd 可读。

这种方法有几个明显的缺点，之前已经从不同的角度讨论过这些缺点。第一个是每个套接字必须与其自己的 fd 关联。无法在多个套接字之间共享等待对象。（这是epoll语义发展的一个主要原因）。第二个是队列在内核中维护，以便 select() 和 poll() 调用可以检查它们。

Libfabric 允许将等待对象与数据队列分离。对于使用 libfabric 接口等待事件的应用程序（例如 fi_cq_sread），这种分离对于应用程序来说大多是隐藏的。例外情况是应用程序可能会收到信号，但读取队列时不会检索到任何事件。这种分离允许队列驻留在应用程序的内存空间中，而等待对象仍然可以使用内核组件。后者的原因是等待对象可以作为系统中断处理的一部分发出信号，这将通过内核驱动程序。

想要在操作系统调用中直接使用本机等待对象（例如文件描述符）的应用程序必须在其处理中执行额外的步骤。为了处理在将事件插入完成或事件对象和向相应的等待对象发出信号之间可能发生的竞争条件，libfabric 定义了一个“fi_trywait()”函数。fi_trywait 实现负责处理潜在的竞争条件，这可能导致应用程序丢失事件或挂起。以下示例演示了 fi_trywait() 的使用。

```
/* Get the native wait object -- an fd in this case */
fi_control(&cq->fid, FI_GETWAIT, (void *) &fd);
FD_ZERO(&fds);
FD_SET(fd, &fds);

while (1) {
    ret = fi_trywait(fabric, &cq->fid, 1);
    if (ret == FI_SUCCESS) {
        /* It’s safe to block on the fd */
        select(fd + 1, &fds, NULL, &fds, &timeout);
    } else if (ret == -FI_EAGAIN) {
        /* Read and process all completions from the CQ */
        do {
            ret = fi_cq_read(cq, &comp, 1);
        } while (ret > 0);
    } else {
        /* something really bad happened */
    }
}
```

在此示例中，应用程序分配了一个 CQ，其中一个 fd 作为其等待对象。它在 fd 上调用 select()。在调用 select() 之前，应用程序必须成功调用 fi_trywait()（返回码 FI_SUCCESS）。成功表示现在可以在本机等待对象上调用阻塞操作，而不必担心应用程序挂起或事件丢失。如果 fi_trywait() 返回 –FI_EAGAIN，通常表示有排队的事件需要处理。

# 环境变量

提供程序使用环境变量来配置内部选项以获得最佳性能或内存消耗。Libfabric 提供了一个用于查询哪些环境变量可用的界面，以及一个将信息显示到命令窗口的应用程序。尽管环境变量通常由管理员配置，但应用程序可以通过编程方式查询变量。

```
/* APIs to query for supported environment variables */
enum fi_param_type {
    FI_PARAM_STRING,
    FI_PARAM_INT,
    FI_PARAM_BOOL,
    FI_PARAM_SIZE_T,
};

struct fi_param {
    /* The name of the environment variable */
    const char *name;
    /* What type of value it stores */
    enum fi_param_type type;
    /* A description of how the variable is used */
    const char *help_string;
    /* The current value of the variable */
    const char *value;
};

int fi_getparams(struct fi_param **params, int *count);
void fi_freeparams(struct fi_param *params);
```

环境变量的修改通常是在较大集群上完成的调整活动。然而，有一些值对开发人员有用。这些可以通过执行 fi_info 命令看到。

```
$ fi_info -e
# FI_LOG_LEVEL: String
# Specify logging level: warn, trace, info, debug (default: warn)

# FI_LOG_PROV: String
# Specify specific provider to log (default: all)

# FI_PROVIDER: String
# Only use specified provider (default: all available)
```

随 libfabric 一起提供的 fi_info 应用程序可用于列出所有提供程序的所有环境变量。“-e”选项将列出所有变量，“-g”选项可用于将输出过滤为仅包含具有匹配子字符串的变量。变量直接记录在代码中，描述可作为 help_string 输出。

FI_LOG_LEVEL 可用于增加 libfabric 和提供程序的调试输出。请注意，在 libfabric 的发行版本中，数据路径操作（传输、接收和完成处理）的调试输出可能不可用。FI_PROVIDER 变量可用于启用或禁用特定的提供程序。这对于确保使用给定的提供程序很有用。

------

[© 2023 OpenFabrics 接口工作组在Jekyll Bootstrap](http://jekyllbootstrap.com/) 和[Twitter Bootstrap](http://twitter.github.com/bootstrap/)的帮助下





